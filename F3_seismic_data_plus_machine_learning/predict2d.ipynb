{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Function for seismic facies prediction using Convolutional Neural Nets (CNN)\n",
    "### By: Charles Rutherford Ildstad\n",
    "### Date: 22.10.2017\n",
    "### For: ConocoPhillips, Tananger,\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Make initial package imports\n",
    "import random\n",
    "import numpy as np\n",
    "import math\n",
    "#\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "\n",
    "from shutil import copyfile\n",
    "\n",
    "# tensorflow\n",
    "import tensorflow as tf\n",
    "# keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import load_model\n",
    "#\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten, Dropout\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.utils  import to_categorical\n",
    "\n",
    "#\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]='0'\n",
    "\n",
    "# for loading segy data, etc.\n",
    "import data_io\n",
    "\n",
    "# Set random seed for reproducability\n",
    "np.random.seed(7)\n",
    "# Confirm backend if in doubt\n",
    "#keras.backend.backend()\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for training or predicting\n",
    "filenames=['F3_entire.segy']    # name of the segy-cube(s) with data , separate by comma 'volume' for additional volumes\n",
    "inp_res = np.float32    # formatting of the input seismic (e.g. np.int8 for 8-bit data, np.float32 for 32-bit data, etc)\n",
    "cube_incr = 32    # number of increments in each direction to create a training cube\n",
    "\n",
    "# SEGY iline/xline/t dimensions:\n",
    "ils=100; ile=750; ili=1\n",
    "xls=300; xle=1250; xli=1\n",
    "ts=4; te=1848; ti=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "# Define the dictionary holding all the training parameters\n",
    "train_dict = {\n",
    "    'files' : ['multi_else_ilxl.pts','multi_grizzly_ilxl.pts','multi_high_amp_continuous_ilxl.pts',\n",
    "               'multi_high_amplitude_ilxl.pts','multi_low_amp_dips_ilxl.pts',\n",
    "               'multi_low_amplitude_ilxl.pts','multi_low_coherency_ilxl.pts',\n",
    "               'multi_salt_ilxl.pts','multi_steep_dips_ilxl.pts'],    # list of names of class-adresses\n",
    "    'num_tot_iterations': 25,    # number of times we draw a new training ensemble/mini-batch\n",
    "    'epochs' : 10,    # number of epochs we run on each training ensemble/mini-batch\n",
    "    'num_train_ex' : 20000,    # number of training examples in each training ensemble/mini-batch\n",
    "    'batch_size' : 32,    # number of training examples fed to the optimizer as a batch\n",
    "    'opt_patience' : 10,    # number of epochs with the same accuracy before force breaking the training ensemble/mini-batch\n",
    "    'data_augmentation' : False,    # whether or not we are using data augmentation\n",
    "    'save_model' : True,    # whether or not we are saving the trained model\n",
    "    'save_location' : 'F3_fullstack_multi_25i_10e_20000'    # file name for the saved trained model\n",
    "}\n",
    "\n",
    "# add directory prefix\n",
    "\n",
    "# 1. dir for classification data\n",
    "classification_data_dir = 'F3_classification_data'\n",
    "# actual classification data file names\n",
    "files_with_dir=[]\n",
    "for file in train_dict['files']:\n",
    "    files_with_dir.append(os.path.join(classification_data_dir, file))\n",
    "train_dict['files'] = files_with_dir\n",
    "\n",
    "# 2. dir for seismic data\n",
    "segy_data_dir = 'F3_seismic_data'\n",
    "# actual file names\n",
    "filenames_with_dir=[]\n",
    "for file in filenames:\n",
    "    filenames_with_dir.append(os.path.join(segy_data_dir, file))\n",
    "filenames = filenames_with_dir\n",
    "\n",
    "# 3. dir for output \n",
    "out_dir = 'F3_output_2D'\n",
    "if not os.path.exists(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "# \n",
    "train_dict['save_location'] = os.path.join(out_dir, train_dict['save_location'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for prediction\n",
    "# Define the dictionary holding all the prediction parameters\n",
    "pred_dict = {\n",
    "    'keras_model' :  load_model(train_dict['save_location']+'.h5'), # input model to be used for prediction, to load a model use: keras.models.load_model('write_location')\n",
    "    #'section_edge' : np.asarray([132, 718, 400, 400, 132, 1720]), # inline and xline section to be predicted (all depths), must contain xline\n",
    "    'section_edge' : np.asarray([339, 339, xls, xle, ts, te]),   # use inline 339\n",
    "    'show_feature' : False,    # Show the distinct features before they are combined to a prediction\n",
    "    'xline' : 400, #123900,    # xline used for classification (index)(should be within section range)\n",
    "    'num_class' : len(train_dict['files']),    # number of classes to output\n",
    "    'cord_syst' : 'segy',    # Coordinate system used, default is 0,0. Set to 'segy' to give inputs in (inline,xline)\n",
    "    'save_pred' : True,    # Save the prediction as a segy-cube\n",
    "    'save_location' : 'F3_fullstack_multi_25i_10e_20000_facies_classes',     # file name for the saved prediction\n",
    "    'pred_batch' : 25,     # number of traces used to make batches of mini-cubes that are stored in memory at once\n",
    "    #'pred_batch' : train_dict['num_train_ex']//(pred_dict['section_edge'][5]-pred_dict['section_edge'][4])    #Suggested value\n",
    "    'pred_prob' : False     # Give the probabilities of the first class(True), or simply show where each class is classified(False)\n",
    "}\n",
    "\n",
    "pred_dict['save_location']  = os.path.join(out_dir, pred_dict['save_location'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# qc segy_decomp\n",
    "segy_obj = segy_decomp(segy_file = filenames[0],\n",
    "                       plot_data = False,\n",
    "                       read_direc = 'full',\n",
    "                       inp_res = np.float32)\n",
    "\n",
    "# If sepcified, plot a given x-line to test the read data\n",
    "# Take a given xline\n",
    "iline = 239\n",
    "data = segy_obj.data[iline, :,:]\n",
    "# Plot the read x-line\n",
    "plt.imshow(data.T,interpolation=\"nearest\", cmap=\"rainbow\", vmin=-15, vmax=15)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ---- Functions for data augmentation ---- (Needs further development)\n",
    "# RotationXY\n",
    "def randomRotationXY(X, max_rot):\n",
    "    max_rot = 6.28318530718 / 360 * max_rot #Deg 2 rad\n",
    "    theta = tf.random_uniform([1], minval=-max_rot, maxval=max_rot, dtype='float32')\n",
    "    x = X[2] * tf.cos(theta) - X[1] * tf.sin(theta)\n",
    "    y = X[2] * tf.sin(theta) + X[1] * tf.cos(theta)\n",
    "    return tf.stack([X[0],y,x])\n",
    "\n",
    "\n",
    "# RotationZ\n",
    "def randomRotationZ(X, max_rot):\n",
    "    max_rot = 6.28318530718 / 360 * max_rot  # Deg 2 rad\n",
    "    theta = tf.random_uniform([1], minval=-max_rot, maxval=max_rot, dtype='float32')\n",
    "    t = X[0] * tf.cos(theta) - X[1] * tf.sin(theta)\n",
    "    x = X[0] * tf.sin(theta) + X[1] * tf.cos(theta)\n",
    "    return tf.stack([t,x,X[2]])\n",
    "\n",
    "\n",
    "# Stretching\n",
    "def randomStretch(window_function, strech):\n",
    "    return tf.cast(window_function,'float32') * (1 + tf.random_uniform([1],minval=-strech,maxval=strech))\n",
    "\n",
    "\n",
    "# Flip\n",
    "def randomFlip(window_function):\n",
    "    should_flip = tf.cast(tf.random_uniform([1], 0, 2, dtype=tf.int32)[0] > 0, tf.bool)\n",
    "    window_function = tf.reverse(window_function, tf.pack([should_flip]))\n",
    "    return window_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert ASCII mask files to volume\n",
    "def class_to_volume_mask(seis_spec, label_list):\n",
    "    \"\"\"\n",
    "    Argument:\n",
    "      seis_spec:  object that holds the specifications of the seismic cube\n",
    "      label_list: list of file names(strings) of adresses for the different classes\n",
    "      \n",
    "    Returns:\n",
    "      mask volume with labels\n",
    "    \"\"\"\n",
    "    # Make the list of class data\n",
    "    print('Making class-adresses')\n",
    "\n",
    "    # class_array: 4-column numpy matrix that adress and class information\n",
    "    class_array = data_io.convert(file_list = label_list,\n",
    "                                  save = False,\n",
    "                                  savename = None,\n",
    "                                  ex_adjust = True)\n",
    "\n",
    "    # Define some boundary parameters given in the input object\n",
    "    inline_start = seis_spec.inl_start\n",
    "    inline_end = seis_spec.inl_end\n",
    "    inline_step = seis_spec.inl_step\n",
    "    #\n",
    "    xline_start = seis_spec.xl_start\n",
    "    xline_end = seis_spec.xl_end\n",
    "    xline_step = seis_spec.xl_step\n",
    "    #\n",
    "    t_start = seis_spec.t_start\n",
    "    t_end = seis_spec.t_end\n",
    "    t_step = seis_spec.t_step\n",
    "\n",
    "    # volume shape\n",
    "    ny = (inline_end-inline_start)//inline_step + 1\n",
    "    nx = (xline_end-xline_start)//xline_step + 1\n",
    "    nt = (t_end-t_start)//t_step + 1\n",
    "    \n",
    "    # mask_arr: 3D numpy array that holds a seismic mask\n",
    "    mask_arr = np.zeros((ny, nx, nt), dtype=np.int8)\n",
    "    \n",
    "        # Make the list of class data\n",
    "    print('Converting class-adresses to mask volume')\n",
    "\n",
    "    # build mask volume\n",
    "    for row in class_array:\n",
    "        y, x, t, label = row\n",
    "        #\n",
    "        iy = (y - inline_start)//inline_step\n",
    "        ix = (x - xline_start)//xline_step\n",
    "        it = (t - t_start)//t_step\n",
    "        #\n",
    "        mask_arr[iy, ix, it] = label\n",
    "        \n",
    "    return mask_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting SEG-Y decompressor\n",
      " SEGY inline/xline/t geometry:\n",
      " ils=100, ile=750, ili=1, ilen=651\n",
      "\n",
      " xls=300, xle=1250, xli=1, xlen=951\n",
      "\n",
      " ts=4, te=1848, ti=4\n",
      "\n",
      "Finished using the SEG-Y decompressor\n"
     ]
    }
   ],
   "source": [
    "# load seismic volume\n",
    "label_list = train_dict['files']\n",
    "segy_obj = data_io.segy_decomp(segy_file = filenames[0], plot_data = False, read_direc = 'full', inp_res = np.float32)\n",
    "\n",
    "# label to volume\n",
    "mask = class_to_volume_mask(segy_obj, label_list)\n",
    "\n",
    "print(mask.shape)\n",
    "np.max(mask[239, :, :]), np.min(mask[239, :, :]), np.count_nonzero(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "def generate_color_map(N=256, normalized=False):\n",
    "    \"\"\"from https://gist.github.com/wllhf/a4533e0adebe57e3ed06d4b50c8419ae .\"\"\"\n",
    "    def bitget(byteval, idx):\n",
    "        return ((byteval & (1 << idx)) != 0)\n",
    "\n",
    "    dtype = 'float32' if normalized else 'uint8'\n",
    "    cmap = np.zeros((N, 3), dtype=dtype)\n",
    "    for i in range(N):\n",
    "        r = g = b = 0\n",
    "        c = i\n",
    "        for j in range(8):\n",
    "            r = r | (bitget(c, 0) << 7 - j)\n",
    "            g = g | (bitget(c, 1) << 7 - j)\n",
    "            b = b | (bitget(c, 2) << 7 - j)\n",
    "            c = c >> 3\n",
    "\n",
    "        cmap[i] = np.array([r, g, b])\n",
    "\n",
    "    cmap = cmap / 255 if normalized else cmap\n",
    "    return cmap\n",
    "#\n",
    "cmap = generate_color_map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(462, 951, 3)\n"
     ]
    }
   ],
   "source": [
    "mask_il_239=mask[239, :, :]\n",
    "segy_data_239=segy_obj.data[239, :, :]\n",
    "\n",
    "#\n",
    "mask1 = np.zeros((mask_il_239.shape[1], mask_il_239.shape[0], 3))\n",
    "for i in range(mask_il_239.shape[0]):\n",
    "    for j in range(mask_il_239.shape[1]):\n",
    "        mask1[j, i, :] = cmap[mask_il_239[i][j]]\n",
    "print(mask1.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x7fc2e8f9fcf8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plt.imshow((mask_il_239.T+segy_data_239.T)*0.5, vmin=0, vmax=8, interpolation='bicubic')\n",
    "plt.imshow(mask1, interpolation='bicubic', vmin=0, vmax=8)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for example creating\n",
    "# Outputs a dictionary with pairs of cube tuples and labels\n",
    "def ex_create(adr_arr,seis_arr,seis_spec,num_examp,cube_incr,inp_res=np.float64,sort_adr = False,replace_illegals = True):\n",
    "    # adr_arr: 4-column numpy matrix that holds a header in the first row, then adress and class information for examples\n",
    "    # seis_arr: 3D numpy array that holds a seismic cube\n",
    "    # seis_spec: object that holds the specifications of the seismic cube;\n",
    "    # num_examp: the number of output mini-cubes that should be created\n",
    "    # cube_incr: the number of increments included in each direction from the example to make a mini-cube\n",
    "    # inp_res: input resolution, the formatting of the seismic cube (could be changed to 8-bit data)\n",
    "    # sort_adr: boolean; whether or not to sort the randomly drawn adresses before making the example cubes\n",
    "    # replace_illegals: boolean; whether or not to draw a new sample in place for an illegal one, or not\n",
    "\n",
    "    # Define the cube size\n",
    "    cube_size = 2*cube_incr+1\n",
    "\n",
    "    # Define some boundary parameters given in the input object\n",
    "    inline_start = seis_spec.inl_start\n",
    "    inline_end = seis_spec.inl_end\n",
    "    inline_step = seis_spec.inl_step\n",
    "    #\n",
    "    xline_start = seis_spec.xl_start\n",
    "    xline_end = seis_spec.xl_end\n",
    "    xline_step = seis_spec.xl_step\n",
    "    #\n",
    "    t_start = seis_spec.t_start\n",
    "    t_end = seis_spec.t_end\n",
    "    t_step = seis_spec.t_step\n",
    "    #\n",
    "    num_channels = seis_spec.cube_num\n",
    "\n",
    "    # Define the buffer zone around the edge of the cube that defines the legal/illegal adresses\n",
    "    inl_min = inline_start + inline_step*cube_incr\n",
    "    inl_max = inline_end - inline_step*cube_incr\n",
    "    #\n",
    "    xl_min = xline_start + xline_step*cube_incr\n",
    "    xl_max = xline_end - xline_step*cube_incr\n",
    "    #\n",
    "    t_min = t_start + t_step*cube_incr\n",
    "    t_max = t_end - t_step*cube_incr\n",
    "\n",
    "    # Print the buffer zone edges\n",
    "    print('Defining the buffer zone:')\n",
    "    print('(inl_min,','inl_max,','xl_min,','xl_max,','t_min,','t_max)')\n",
    "    print('(',inl_min,',',inl_max,',',xl_min,',',xl_max,',',t_min,',',t_max,')')\n",
    "    \n",
    "    # Also give the buffer values in terms of indexes\n",
    "    print('(', cube_incr,',',((xline_end-xline_start)//xline_step) - cube_incr,\\\n",
    "          ',',cube_incr,',',((t_end-t_start)//t_step) - cube_incr,')')\n",
    "\n",
    "    # We preallocate the function outputs; a list of examples and a list of labels\n",
    "    examples = np.empty((num_examp,cube_size,cube_size,num_channels),dtype=inp_res)\n",
    "    labels = np.empty(num_examp,dtype=np.int8)\n",
    "\n",
    "    # If we want to stack the examples in the third dimension we use the following example preallocation in stead\n",
    "    # examples = np.empty((num_examp*(cube_size),(cube_size),(cube_size)),dtype=inp_res)\n",
    "\n",
    "    # Generate a random list of indexes to be drawn, and make sure it only takes a legal amount of examples\n",
    "    try:\n",
    "        max_row_idx = len(adr_arr)-1\n",
    "        rand_idx = random.sample(range(0, max_row_idx), num_examp)\n",
    "        # NOTE: Could be faster to sort indexes before making examples for algorithm optimization\n",
    "        if sort_adr:\n",
    "            rand_idx.sort()\n",
    "    except ValueError:\n",
    "        print('Sample size exceeded population size.')\n",
    "\n",
    "    # Make an iterator for when the lists should become shorter(if we have replacement of illegals or not)\n",
    "    n=0\n",
    "    for i in range(num_examp):\n",
    "        # Get a random in-line, x-line, and time value, and store the label\n",
    "        # Make sure there is room for an example at this index\n",
    "        for j in range(50):\n",
    "            adr = adr_arr[rand_idx[i]]\n",
    "            # Check that the given example is within the legal zone\n",
    "            if (adr[0]>=inl_min and adr[0]<inl_max) and \\\n",
    "                (adr[1]>=xl_min and adr[1]<xl_max) and \\\n",
    "                (adr[2]>=t_min and adr[2]<t_max):\n",
    "                # Make the example for the given address\n",
    "                # Convert the adresses to indexes and store the examples in the 4th dimension\n",
    "                idx = [(adr[0]-inline_start)//inline_step,(adr[1]-xline_start)//xline_step,(adr[2]-t_start)//t_step]\n",
    "\n",
    "\n",
    "                examples[i-n,:,:,:] = seis_arr[idx[0],\\\n",
    "                                               idx[1]-cube_incr:idx[1]+cube_incr+1,\\\n",
    "                                               idx[2]-cube_incr:idx[2]+cube_incr+1,:]\n",
    "\n",
    "                # Put the cube and label into the lists\n",
    "                labels[i-n] = adr[-1]\n",
    "\n",
    "                # Alternatively; stack the examples in the third dimension\n",
    "                #datasets[(i-n)*(cube_size):(i-n+1)*(cube_size),:,:] = ex\n",
    "                break\n",
    "            else:\n",
    "                # If we want to replace the illegals, draw again\n",
    "                if replace_illegals:\n",
    "                    rand_idx[i] = random.randint(0,max_row_idx)\n",
    "                else:\n",
    "                    # if not, just make the output lists shorter\n",
    "                    n += 1\n",
    "                    break\n",
    "\n",
    "            if j == 50:\n",
    "                # If we can't get a proper cube in 50 consequtive tries\n",
    "                print('Badly conditioned dataset!')\n",
    "\n",
    "    # Slice the data if desired\n",
    "    #labels = labels[0:i-n+1]\n",
    "    #examples = examples[0:i-n+1,:,:,:]\n",
    "\n",
    "    # Return the output list/tuple (slice it if it has been shortened)\n",
    "    # (numSamples, nxline, nz, nch)\n",
    "    return (examples[0:i-n+1,:,:,:], labels[0:i-n+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that takes the epoch as input and returns the desired learning rate\n",
    "def adaptive_lr(input_int):\n",
    "    # input_int: the epoch that is currently being entered\n",
    "\n",
    "    # define the learning rate (quite arbitrarily decaying)\n",
    "    lr = 0.1**input_int\n",
    "\n",
    "    #return the learning rate\n",
    "    return lr\n",
    "\n",
    "\n",
    "# Make the network structure and outline, and train it\n",
    "def train_model(segy_obj,class_array,num_classes,cube_incr,inp_res = np.float64,\\\n",
    "                num_bunch = 10,num_epochs = 100,num_examples = 10000,batch_size = 32,\\\n",
    "                opt_patience = 5, data_augmentation=False,num_channels = 1,\\\n",
    "                keras_model = None,write_out = False,write_location = 'default_write'):\n",
    "    # segy_obj: Object returned from the segy_decomp function\n",
    "    # class_array: numpy array of class adresses and type, returned from the convert function\n",
    "    # num_classes: number of destinct classes we are training on\n",
    "    # cube_incr: number of increments included in each direction from the example to make a mini-cube\n",
    "    # inp_res: input resolution, the formatting of the seismic cube (could be changed to 8-bit data)\n",
    "    # num_bunch: number of times we draw a new ensemble of training data and train on it\n",
    "    # num_epochs: number of epochs we train on a given ensemble of training data\n",
    "    # num_examples: number of examples we draw in an ensemble\n",
    "    # batch_size: number of mini-batches we go through at a time from the number of examples\n",
    "    # opt_patience: epochs that can pass without improvement in accuracy before the system breaks the loop\n",
    "    # data_augmentation: boolean which determines whether or not to apply augmentation on the examples\n",
    "    # num_channels: number of segy-cubes we have imported simultaneously\n",
    "    # keras_model: existing keras model to be improved if the user wants to improve and not create a new model\n",
    "    # write_out: boolean; save the trained model to disk or not,\n",
    "    # write_location: desired location on the disk for the model to be saved\n",
    "\n",
    "    # Check if the user wants to make a new model, or train an existing input model\n",
    "    if keras_model == None:\n",
    "        # Begin setting up model architecture and parameters\n",
    "        cube_size = 2*cube_incr+1\n",
    "\n",
    "        #  This model is loosely built after that of Anders Waldeland (5 Convolutional layers\n",
    "        #  and 2 fully connected layers with rectified linear and softmax activations)\n",
    "        # We have added drop out and batch normalization our selves, and experimented with multi-prediction\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(50, (5, 5), padding='same', input_shape=(cube_size,cube_size,num_channels), \\\n",
    "                         strides=(4, 4), data_format=\"channels_last\",name = 'conv_layer1'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Conv2D(50, (3, 3), strides=(2, 2), padding = 'same',name = 'conv_layer2'))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Conv2D(50, (3, 3), strides=(2, 2), padding= 'same',name = 'conv_layer3'))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Conv2D(50, (3, 3), strides=(2, 2), padding= 'same',name = 'conv_layer4'))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Conv2D(50, (3, 3), strides=(2, 2), padding= 'same',name = 'conv_layer5'))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(50,name = 'dense_layer1'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dense(10,name = 'attribute_layer'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dense(num_classes, name = 'pre-softmax_layer'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('softmax'))\n",
    "\n",
    "        # initiate the Adam optimizer with a given learning rate (Note that this is adapted later)\n",
    "        opt = keras.optimizers.adam(lr=0.001)\n",
    "\n",
    "        # Compile the model with the desired loss, optimizer, and metric\n",
    "        model.compile(loss='categorical_crossentropy',\n",
    "                      optimizer=opt,\n",
    "                      metrics=['accuracy'])\n",
    "    else:\n",
    "        # Define the model we are performing training on as the input model\n",
    "        model = keras_model\n",
    "\n",
    "    # Print the training summary\n",
    "    print(model.summary())\n",
    "\n",
    "\n",
    "    ### Begin actual model training\n",
    "    # Define some initial parameters, and the early stopping and adaptive learning rate callback\n",
    "    early_stopping = EarlyStopping(monitor='acc', patience=opt_patience)\n",
    "    LR_sched = LearningRateScheduler(schedule = adaptive_lr)\n",
    "\n",
    "    # Potential for adding tensor board functionality to see the change of parameters with time\n",
    "    #tensor_board = TensorBoard(log_dir='./logs', histogram_freq=1, batch_size=32,\\\n",
    "    #                            write_graph=True, write_grads=True, write_images=True,\\\n",
    "    #                            embeddings_freq=1, embeddings_layer_names=None, embeddings_metadata=None)\n",
    "\n",
    "    # Start the timer for the training iterations\n",
    "    start = time.time()\n",
    "\n",
    "    # Train the model\n",
    "    for i in range(num_bunch):\n",
    "        # Give an update as to how many times we have drawn a new example set\n",
    "        print('Iteration number:',i+1,'/',num_bunch)\n",
    "\n",
    "        # Make the examples\n",
    "        print('Starting training data creation:')\n",
    "        (x_train, y_train) = ex_create(adr_arr = class_array,\n",
    "                                       seis_arr = segy_obj.data,\n",
    "                                       seis_spec = segy_obj,\n",
    "                                       num_examp = num_examples,\n",
    "                                       cube_incr = cube_incr,\n",
    "                                       inp_res = inp_res,\n",
    "                                       sort_adr = False,\n",
    "                                       replace_illegals = True)\n",
    "\n",
    "        print('Finished creating',num_examples,'examples!')\n",
    "\n",
    "        # Define and reshape the training data\n",
    "        # x_train = np.expand_dims(x_train,axis=4)\n",
    "\n",
    "        # Convert labels to one-hot encoding(and if necessary change the data type and scale as needed)\n",
    "        y_train = to_categorical(y_train, num_classes)\n",
    "\n",
    "        # See if the user has chosen to implement data_augmentation and implement it if so\n",
    "        if not data_augmentation:\n",
    "            print('Not using data augmentation.')\n",
    "            # Run the model training\n",
    "            history = model.fit(x=x_train,\n",
    "                                y=y_train,\n",
    "                                batch_size=batch_size,\n",
    "                                validation_split=0.2,\n",
    "                                callbacks=[early_stopping, LR_sched],\n",
    "                                epochs=num_epochs,\n",
    "                                shuffle=True)\n",
    "\n",
    "        else:\n",
    "            # !!! Currently does not work\n",
    "            print('Using real-time data augmentation.')\n",
    "            # This will do preprocessing and realtime data augmentation\n",
    "            datagen = ImageDataGenerator(featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "                                         samplewise_center=False,  # set each sample mean to 0\n",
    "                                         featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "                                         samplewise_std_normalization=False,  # divide each input by its std\n",
    "                                         zca_whitening=False,  # apply ZCA whitening\n",
    "                                         rotation_range=20,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "                                         width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\n",
    "                                         height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)\n",
    "                                         horizontal_flip=True,  # randomly flip images\n",
    "                                         vertical_flip=False,    # randomly flip images\n",
    "                                         shear_range = 0.349, # shear intensity (counter-clockwise direction in radians)\n",
    "                                         zoom_range = 0.2,   # range for random zoom (float)\n",
    "                                         rescale = 1.5)  # rescaling factor which multiplies data by the value provided\n",
    "\n",
    "            # Compute quantities required for feature-wise normalization\n",
    "            # (std, mean, and principal components if ZCA whitening is applied).\n",
    "            datagen.fit(x_train)\n",
    "\n",
    "            # Fit the model on the batches generated by datagen.flow().\n",
    "            history = model.fit_generator(datagen.flow(x_train,\n",
    "                                                       y_train,\n",
    "                                                       batch_size = batch_size),\n",
    "                                          steps_per_epoch = x_train.shape[0] // batch_size,\n",
    "                                          epochs = num_epochs,\n",
    "                                          validation_data = (x_test, y_test))\n",
    "\n",
    "\n",
    "\n",
    "        # Set the time for one training iteration\n",
    "        if i == 0:\n",
    "            end = time.time()\n",
    "            tot_time = (end-start)*num_bunch\n",
    "\n",
    "\n",
    "\n",
    "        # Give an update on the time remaining\n",
    "        rem_time = ((num_bunch-(i+1))/num_bunch)*tot_time\n",
    "\n",
    "        if rem_time <= 300:\n",
    "            print('Approximate time remaining of the training:',rem_time,' sec.')\n",
    "        elif 300 < rem_time <= 60*60:\n",
    "            minutes = rem_time//60\n",
    "            seconds = (rem_time%60)*(60/100)\n",
    "            print('Approximate time remaining of the training:',minutes,' min., ',seconds,' sec.')\n",
    "        elif 60*60 < rem_time <= 60*60*24:\n",
    "            hours = rem_time//(60*60)\n",
    "            minutes = (rem_time%(60*60))*(1/60)*(60/100)\n",
    "            print('Approximate time remaining of the training:',hours,' hrs., ',minutes,' min., ')\n",
    "        else:\n",
    "            days = time_rem//(24*60*60)\n",
    "            hours = (time_rem%(24*60*60))*(1/60)*((1/60))*(24/100)\n",
    "            print('Approximate time remaining of the training:',days,' days, ',hours,' hrs., ')\n",
    "\n",
    "\n",
    "    # Save the trained model if the user has chosen to do so\n",
    "    if write_out:\n",
    "        print('Saving model: ...')\n",
    "        model.save(write_location + '.h5')\n",
    "        print('Model saved.')\n",
    "\n",
    "\n",
    "    # Return the trained model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ---- Functions for the prediction part of the program ----\n",
    "# Parse the cube into sub-cubes suitable as model input\n",
    "def cube_parse(seis_arr,cube_incr,inp_res = np.float64, mode = 'trace', padding = False,\\\n",
    "               conc = False, inline_num = 0, xline_num = 0, depth = 0):\n",
    "    # seis_arr: a 3D numpy array that holds a seismic cube\n",
    "    # cube_incr: number of increments included in each direction from the example to make a mini-cube\n",
    "    # inp_res: input resolution, the formatting of the seismic cube (could be changed to 8-bit data)\n",
    "    # mode: how much of the 3D-cube should be converted to examples ('full','xline','inline','trace', or 'point')\n",
    "    # padding: do we want to pad the zone which is outside our buffer with zeroes?\n",
    "    # conc: do we want to concattenate the examples, or store them in the same matrix they were fed to us?\n",
    "    # inline_num: if mode is inline or point; what inline do we use?\n",
    "    # xline_num: if mode is xline or point; what xline do we use?\n",
    "    # depth: if mode is point; what depth do we use?\n",
    "\n",
    "    # Make some initial definitions wrt. dimensionality\n",
    "    inls = seis_arr.shape[0]\n",
    "    xls = seis_arr.shape[1]\n",
    "    zls = seis_arr.shape[2]\n",
    "    num_channels = seis_arr.shape[3]\n",
    "    #\n",
    "    cube_size = 2*cube_incr+1\n",
    "\n",
    "    # Define the indent where the saved data will start, if user wants padding this is 0, else it is cube_incr\n",
    "    if padding:\n",
    "        i_re = 0\n",
    "        x_re = 0\n",
    "        z_re = 0\n",
    "        # Preallocate the output array, if concatenated it's 4 dimensional, if not it's 6 dimensional\n",
    "        if conc:\n",
    "            # Make adjustments to the parameters so that we iterate over the right number of samples, etc.\n",
    "            if mode == 'full':\n",
    "                examples = np.zeros((inls*xls*zls,cube_size,cube_size,num_channels),dtype=inp_res)\n",
    "            elif mode == 'inline':\n",
    "                examples = np.zeros((xls*zls,cube_size,cube_size,num_channels),dtype=inp_res)\n",
    "                x_re = cube_incr\n",
    "            elif mode == 'xline':\n",
    "                examples = np.zeros((inls*zls,cube_size,cube_size,num_channels),dtype=inp_res)\n",
    "                i_re = cube_incr\n",
    "            elif mode == 'trace':\n",
    "                examples = np.zeros((zls,cube_size,cube_size,num_channels),dtype=inp_res)\n",
    "                i_re = cube_incr\n",
    "                x_re = cube_incr\n",
    "            elif mode == 'point':\n",
    "                examples = np.zeros((1,cube_size,cube_size,num_channels),dtype=inp_res)\n",
    "                i_re = cube_incr\n",
    "                x_re = cube_incr\n",
    "                z_re = cube_incr\n",
    "            else:\n",
    "                print('ERROR: invalid mode! use: ''full'',''xline'',''inline'',''trace'', or ''point''')\n",
    "            # Take into account that we will have a total smaller dimensionality of data due to illegals\n",
    "            inls -= 2*cube_incr\n",
    "            xls -= 2*cube_incr\n",
    "            zls -= 2*cube_incr\n",
    "        else:\n",
    "            # Make adjustments to the parameters so that we iterate over the right number of samples, etc.\n",
    "            if mode == 'full':\n",
    "                examples = np.zeros((inls,xls,zls,cube_size,cube_size,num_channels),dtype=inp_res)\n",
    "            elif mode == 'inline':\n",
    "                examples = np.zeros((1,xls,zls,cube_size,cube_size,num_channels),dtype=inp_res)\n",
    "                x_re = cube_incr\n",
    "            elif mode == 'xline':\n",
    "                examples = np.zeros((inls,1,zls,cube_size,cube_size,num_channels),dtype=inp_res)\n",
    "                i_re = cube_incr\n",
    "            elif mode == 'trace':\n",
    "                examples = np.zeros((1,1,zls,cube_size,cube_size,num_channels),dtype=inp_res)\n",
    "                i_re = cube_incr\n",
    "                x_re = cube_incr\n",
    "            elif mode == 'point':\n",
    "                examples = np.zeros((1,1,1,cube_size,cube_size,num_channels),dtype=inp_res)\n",
    "                i_re = cube_incr\n",
    "                x_re = cube_incr\n",
    "                z_re = cube_incr\n",
    "            else:\n",
    "                print('ERROR: invalid mode! use: ''full'',''xline'',''inline'',''trace'', or ''point''')\n",
    "    else:\n",
    "        i_re = cube_incr\n",
    "        x_re = cube_incr\n",
    "        z_re = cube_incr\n",
    "        # Preallocate the output array, if concatenated it's 5 dimensional, if not it's 7 dimensional\n",
    "        if conc:\n",
    "            # Make adjustments to the parameters so that we iterate over the right number of samples, etc.\n",
    "            if mode == 'full':\n",
    "                examples = np.empty(((inls-2*cube_incr)*(xls-2*cube_incr)*(zls-2*cube_incr),cube_size,cube_size,num_channels),\\\n",
    "                                   dtype=inp_res)\n",
    "            elif mode == 'inline':\n",
    "                examples = np.empty(((xls-2*cube_incr)*(zls-2*cube_incr),cube_size,cube_size,num_channels),\\\n",
    "                                   dtype=inp_res)\n",
    "                inline_num -= cube_incr\n",
    "                xline_num = 0\n",
    "                depth = 0\n",
    "            elif mode == 'xline':\n",
    "                examples = np.empty(((inls-2*cube_incr)*(zls-2*cube_incr),cube_size,cube_size,num_channels),\\\n",
    "                                   dtype=inp_res)\n",
    "                inline_num = 0\n",
    "                xline_num -= cube_incr\n",
    "                depth = 0\n",
    "            elif mode == 'trace':\n",
    "                examples = np.empty((zls-2*cube_incr,cube_size,cube_size,num_channels),dtype=inp_res)\n",
    "                inline_num -= cube_incr\n",
    "                xline_num -= cube_incr\n",
    "                depth = 0\n",
    "            elif mode == 'point':\n",
    "                examples = np.empty((1,cube_size,cube_size,num_channels),dtype=inp_res)\n",
    "                inline_num -= cube_incr\n",
    "                xline_num -= cube_incr\n",
    "                depth -= cube_incr\n",
    "            else:\n",
    "                print('ERROR: invalid mode! use: ''full'',''xline'',''inline'',''trace'', or ''point''')\n",
    "            # Take into account that we will have a total smaller dimensionality of data due to illegals\n",
    "            inls -= 2*cube_incr\n",
    "            xls -= 2*cube_incr\n",
    "            zls -= 2*cube_incr\n",
    "        else:\n",
    "            if mode == 'full':\n",
    "                examples = np.empty(((inls-2*cube_incr),(xls-2*cube_incr),(zls-2*cube_incr),cube_size,cube_size,cube_size,num_channels),\\\n",
    "                                   dtype=inp_res)\n",
    "            elif mode == 'inline':\n",
    "                examples = np.empty((1,(xls-2*cube_incr),(zls-2*cube_incr),cube_size,cube_size,cube_size,num_channels),\\\n",
    "                                   dtype=inp_res)\n",
    "            elif mode == 'xline':\n",
    "                examples = np.empty(((inls-2*cube_incr),1,(zls-2*cube_incr),cube_size,cube_size,cube_size,num_channels),\\\n",
    "                                   dtype=inp_res)\n",
    "            elif mode == 'trace':\n",
    "                examples = np.empty((1,1,(zls-2*cube_incr),cube_size,cube_size,cube_size,num_channels),dtype=inp_res)\n",
    "            elif mode == 'point':\n",
    "                examples = np.empty((1,1,1,cube_size,cube_size,cube_size,num_channels),dtype=inp_res)\n",
    "            else:\n",
    "                print('ERROR: invalid mode! use: ''full'',''xline'',''inline'',''trace'', or ''point''')\n",
    "\n",
    "\n",
    "    # Iterate through the desired section of the 3D input array, create the example cubes, and store them as desired\n",
    "    if conc:\n",
    "        for j in range(cube_incr, xls+cube_incr):\n",
    "            for k in range(cube_incr, zls+cube_incr):\n",
    "                #print('---------cube_incr={}, inline_num={}, k={}, depth={}\\n'.format(cube_incr, inline_num, k, depth))\n",
    "                cc = seis_arr[inline_num:inline_num+1,\\\n",
    "                              j-cube_incr+xline_num:j+cube_incr+xline_num+1,\\\n",
    "                              k-cube_incr+depth:k+cube_incr+depth+1,:]\n",
    "                #print(' examples shape:{}, cc shape:{}, z1: {}, z2: {} \\n'.format(examples.shape, cc.shape, k-cube_incr+depth, k+cube_incr+depth+1))\n",
    "                #\n",
    "                examples[(j-x_re)*xls+k-z_re,:,:,:] = cc\n",
    "\n",
    "                # Make sure we stop after the appropriate number of iterations\n",
    "                if mode == 'point':\n",
    "                    break\n",
    "            if mode == 'point' or mode == 'trace':\n",
    "                break\n",
    "\n",
    "    else:\n",
    "        # Make the cubes\n",
    "        for i in range(cube_incr, inls-cube_incr):\n",
    "            if mode == 'xline':\n",
    "                for k in range(cube_incr, zls-cube_incr):\n",
    "                    examples[i-i_re,1,k-z_re,:,:,:] = seis_arr[i-cube_incr:i+cube_incr+1,\\\n",
    "                                                                 xline_num-cube_incr:xline_num+cube_incr+1,\\\n",
    "                                                                 k-cube_incr:k+cube_incr+1,:]\n",
    "            else:\n",
    "                for j in range(cube_incr, xls-cube_incr):\n",
    "                    for k in range(cube_incr, zls-cube_incr):\n",
    "                        examples[i-i_re,j-x_re,k-z_re,:,:,:] = seis_arr[i+inline_num-cube_incr:i+inline_num+cube_incr+1,\\\n",
    "                                                                          j+xline_num-cube_incr:j+xline_num+cube_incr+1,\\\n",
    "                                                                          k+depth-cube_incr:k+depth+cube_incr+1,:]\n",
    "\n",
    "                        # Make sure we stop after the appropriate number of iterations\n",
    "                        if mode == 'point':\n",
    "                            break\n",
    "                    if mode == 'point' or mode == 'trace':\n",
    "                        break\n",
    "                if mode == 'point' or mode == 'trace' or mode == 'inline':\n",
    "                    break\n",
    "\n",
    "\n",
    "    # Return the list of examples stored as the desired type of array\n",
    "    return examples\n",
    "\n",
    "\n",
    "\n",
    "# Make an intermediate output model to check filters\n",
    "def makeIntermediate(keras_model,layer_name):\n",
    "    # keras_model: keras model that has been trained previously\n",
    "    # layer_name: name of the layer with the desired output\n",
    "\n",
    "    # Define the new model that stops at the desired layer\n",
    "    intermediate_layer_model = Model(inputs=keras_model.input,\\\n",
    "                                     outputs=keras_model.get_layer(layer_name).output)\n",
    "\n",
    "    # Return the newly defined model\n",
    "    return intermediate_layer_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the output class of the given input traces\n",
    "def predicting(filename,inp_seis,seis_obj,keras_model,cube_incr,num_classes,inp_res=np.float64,mode='xline',\\\n",
    "               section=np.asarray([0,0,0,0,0,0]),line_num=0, print_segy = False,savename = 'default_write',\\\n",
    "               pred_batch = 1,show_features = False, layer_name='attribute_layer', show_prob = False):\n",
    "    # filename: filename of the segy-cube to be imported (necessary for copying the segy-frame before writing a new segy)\n",
    "    # inp_seis: a 3D numpy array that holds the input seismic cube\n",
    "    # seis_obj: Object returned from the segy_decomp function\n",
    "    # keras_model: keras model that has been trained previously\n",
    "    # cube_incr: number of increments included in each direction from the example to make a mini-cube\n",
    "    # num_classes: num_classes: number of destinct classes we are training on\n",
    "    # inp_res: input resolution, the formatting of the seismic cube (could be changed to 8-bit data)\n",
    "    # mode: what part of the cube to predict along; 'inline', 'xline', 'section, or 'full' (entire cube)\n",
    "    # section: edge locations(index) of the sub-section (min. inline, max. inline, min. xline, max xline, min z, max z)\n",
    "    # line_num: xline/inline number to predict along\n",
    "    # print_segy: whether or not to save the prediction as a segy, npy and csv file (previously just segy)\n",
    "    # savename: name of the files to be saved (extensions are added automatically)\n",
    "    # pred_batch: number of traces to predict on at a time\n",
    "    # show_features: whether or not to get the features or the classes\n",
    "    # layer_name: optionally give a different layer to get the features from (name defined in keras.model)\n",
    "    # show_prob: if the user wants to get out probabilities or classifications\n",
    "\n",
    "    # Define some initial parameters\n",
    "    num_channels = seis_obj.cube_num\n",
    "    inls = inp_seis.shape[0]\n",
    "    xls = inp_seis.shape[1]\n",
    "    zls = inp_seis.shape[2]\n",
    "    #\n",
    "    cube_size = 2*cube_incr+1\n",
    "\n",
    "    # If the user simply wants the classification we only need 1 value for each input point,\n",
    "    if not show_prob:\n",
    "        num_classes = 1\n",
    "\n",
    "    # Read the section needed for prediction depending on the mode\n",
    "    if mode == 'inline':\n",
    "        section_edge = np.asarray([line_num,line_num,cube_incr,xls-cube_incr,cube_incr,zls-cube_incr])\n",
    "    elif mode == 'xline':\n",
    "        section_edge = np.asarray([cube_incr,inls-cube_incr,line_num,line_num,cube_incr,zls-cube_incr])\n",
    "    elif mode == 'section':\n",
    "        section_edge = section\n",
    "    elif mode == 'full':\n",
    "        section_edge = np.asarray([cube_incr,inls-cube_incr,cube_incr,xls-cube_incr,cube_incr,zls-cube_incr])\n",
    "    else:\n",
    "        print('invalid mode, please input inline, xline, section, or full')\n",
    "\n",
    "    # Preallocate the full prediction array and if the user wants to show the features make the intermediate model,\n",
    "    if show_features:\n",
    "        intermediate_layer_model = Model(inputs=keras_model.input,\n",
    "                                         outputs=keras_model.get_layer(layer_name).output)\n",
    "        prediction = np.empty((\\\n",
    "            (section_edge[5]-section_edge[4]+1)*(section_edge[3]-section_edge[2]+1)*(section_edge[1]-section_edge[0]+1),10),\\\n",
    "                              dtype=np.float32)\n",
    "    else:\n",
    "        prediction = np.empty((\\\n",
    "            (section_edge[5]-section_edge[4]+1)*(section_edge[3]-section_edge[2]+1)*(section_edge[1]-section_edge[0]+1),\\\n",
    "                               num_classes),dtype=np.float32)\n",
    "\n",
    "    # Preallocate the data array to fill for each batch and initiate iterators\n",
    "    data = np.empty((pred_batch*(section_edge[5]-section_edge[4]+1),cube_size,cube_size,num_channels), dtype=inp_res)\n",
    "    indx = 0\n",
    "    jndx = 0\n",
    "\n",
    "    # Calculate how many sets of batches need to be done and define parameters needed for the final batch\n",
    "    tot_len = (section_edge[1]-section_edge[0]+1)*(section_edge[3]-section_edge[2]+1)  # nx0*ny0\n",
    "    rem = tot_len % pred_batch\n",
    "    num_it = tot_len // pred_batch\n",
    "    # Time the sub_prediction\n",
    "    start = time.time()\n",
    "\n",
    "    # Start making sub-cubes from the input traces and store then in the data array\n",
    "    print('Retrieving to memory:')\n",
    "    for il_num in range(section_edge[0],section_edge[1]+1):\n",
    "        # Make a progres update for the inline number\n",
    "        print('inline-num:',il_num-section_edge[0]+1,'/',section_edge[1]-section_edge[0]+1)\n",
    "        for xl_num in range(section_edge[2],section_edge[3]+1):\n",
    "            # Make a progres update for the xline number\n",
    "            print('xline-num:',xl_num-section_edge[2]+1,'/',section_edge[3]-section_edge[2]+1)\n",
    "            for z_num in range(section_edge[5]-section_edge[4]+1):\n",
    "                \n",
    "                #print(\" ---- z_num={}, depth = {}\\n\".format(z_num, z_num+section_edge[4]))\n",
    "                # Call the cube_parse function to get the cubes corresponding to the current point\n",
    "                data[indx*(section_edge[5]-section_edge[4]+1)+z_num,:,:,:] = cube_parse(seis_arr = inp_seis,\n",
    "                                                                                        cube_incr = cube_incr,\n",
    "                                                                                        inp_res = inp_res,\n",
    "                                                                                        mode = 'point',\n",
    "                                                                                        padding = False,\n",
    "                                                                                        conc = True,\n",
    "                                                                                        inline_num = il_num,\n",
    "                                                                                        xline_num = xl_num,\n",
    "                                                                                        depth = z_num+section_edge[4])\n",
    "\n",
    "            # Check if we have filled up the data array and need to do a prediction\n",
    "            if (indx+1) % pred_batch == 0:\n",
    "                print('Making prediction on sub-section:')\n",
    "\n",
    "                # Predict the given class or features dependant on the user input\n",
    "                if show_features:\n",
    "                    prediction[jndx*(pred_batch*(section_edge[5]-section_edge[4]+1)):\\\n",
    "                              (jndx+1)*(pred_batch*(section_edge[5]-section_edge[4]+1)),:] = \\\n",
    "                                    intermediate_layer_model.predict((data))\n",
    "\n",
    "                else:\n",
    "                    if show_prob:\n",
    "                        # Simple model prediction with probabilities\n",
    "                        prediction[jndx*(pred_batch*(section_edge[5]-section_edge[4]+1)):\\\n",
    "                                   (jndx+1)*(pred_batch*(section_edge[5]-section_edge[4]+1)),:] = \\\n",
    "                        keras_model.predict((data))\n",
    "                    else:\n",
    "                        # Model prediction of classes\n",
    "                        prediction[jndx*(pred_batch*(section_edge[5]-section_edge[4]+1)):\\\n",
    "                                   (jndx+1)*(pred_batch*(section_edge[5]-section_edge[4]+1)),:] = \\\n",
    "                        np.expand_dims(keras_model.predict_classes((data)),axis = 1)\n",
    "\n",
    "                # Tell the user the section is finished\n",
    "                print('Section finished!')\n",
    "\n",
    "                if jndx == 0:\n",
    "                    # Finish the timer and calculate how long the user should expect the program to take:\n",
    "                    end = time.time()\n",
    "                    DT = end-start # seconds per iteration\n",
    "                    tot_time = num_it*DT+(rem/pred_batch)*DT #seconds\n",
    "\n",
    "                # Give the user an update regarding the time remaining\n",
    "                time_rem = (tot_time-DT*(jndx+1))\n",
    "                if time_rem <= 300:\n",
    "                    print('Approximate time remaining of the prediction:',time_rem, ' sec.')\n",
    "                elif 300 < time_rem <= 60*60:\n",
    "                    minutes = time_rem//60\n",
    "                    seconds = (time_rem%60)*(60/100)\n",
    "                    print('Approximate time remaining of the prediction:',minutes,' min., ',seconds,' sec.')\n",
    "                elif 60*60 < time_rem <= 60*60*24:\n",
    "                    hours = time_rem//(60*60)\n",
    "                    minutes = (time_rem%(60*60))*(1/60)*(60/100)\n",
    "                    print('Approximate time remaining of the prediction:',hours,' hrs., ',minutes,' min., ')\n",
    "                else:\n",
    "                    days = time_rem//(24*60*60)\n",
    "                    hours = (time_rem%(24*60*60))*(1/60)*((1/60))*(24/100)\n",
    "                    print('Approximate time remaining of the prediction:',days,' days, ',hours,' hrs., ')\n",
    "\n",
    "\n",
    "                # Update iterators and give updates to user\n",
    "                indx = 0\n",
    "                jndx+=1\n",
    "                print('Retrieving to memory:')\n",
    "\n",
    "            # Check if we have exhausted the range of data to be predicted and need to finish the function\n",
    "            elif jndx == num_it and indx == rem-1:\n",
    "                # Slice the data array to only include the relevant part\n",
    "                data = data[:indx*(section_edge[5]-section_edge[4]+1)+z_num+1]\n",
    "\n",
    "                print('Finalizing prediction:')\n",
    "\n",
    "                # Make the final prediction\n",
    "                if show_features:\n",
    "                    prediction[jndx*(pred_batch*(section_edge[5]-section_edge[4]+1)):,:] = \\\n",
    "                                    intermediate_layer_model.predict((data))\n",
    "                else:\n",
    "                    if show_prob:\n",
    "                        prediction[jndx*(pred_batch*(section_edge[5]-section_edge[4]+1)):,:] = \\\n",
    "                                    keras_model.predict((data))\n",
    "                    else:\n",
    "                        prediction[jndx*(pred_batch*(section_edge[5]-section_edge[4]+1)):,:] = \\\n",
    "                                    np.expand_dims(keras_model.predict_classes((data)),axis = 1)\n",
    "\n",
    "            # If we should keep filling the data and not predict yet, simply increase the iterator\n",
    "            else:\n",
    "                indx+=1\n",
    "\n",
    "    # Reshape the prediction to the shape of the desired cube\n",
    "    print('Reshaping prediction:')\n",
    "    \n",
    "    # ny0, nx0, nz0, num_classes\n",
    "    if show_features:\n",
    "        prediction = prediction.reshape((section_edge[1]-section_edge[0]+1,\\\n",
    "                                         section_edge[3]-section_edge[2]+1,\\\n",
    "                                         section_edge[5]-section_edge[4]+1,10),order='C')\n",
    "    else:\n",
    "        prediction = prediction.reshape((section_edge[1]-section_edge[0]+1,\\\n",
    "                                         section_edge[3]-section_edge[2]+1,\\\n",
    "                                         section_edge[5]-section_edge[4]+1,num_classes),order='C')\n",
    "\n",
    "    print('Prediction finished!', ' shape={}-{}-{}-{}'.format(prediction.shape[0], prediction.shape[1], \n",
    "                                                              prediction.shape[2], prediction.shape[3]))\n",
    "\n",
    "    # Save the prediction as a segy, numpy and csv file\n",
    "    # NOTE: Everything SEGY and CSV is made into 32bit-float to conform to commonly used reading programs\n",
    "    if print_segy:\n",
    "        # Update the data we send to the saver functions dependant on what we have predicted\n",
    "        if show_prob:\n",
    "            class_row = 1\n",
    "        else:\n",
    "            class_row = 0\n",
    "\n",
    "        print('Saving prediction: ...')\n",
    "\n",
    "        # Save the numpy file\n",
    "        np.save(savename + '.npy', prediction)\n",
    "\n",
    "        # Get the right filename in case the input is given as a list\n",
    "        if type(filename) is list:\n",
    "            # Save the segy file using the input filename as a framework\n",
    "            # Just use the first member of the list as the reference\n",
    "            input_file = filename[0]\n",
    "        else:\n",
    "            # Save the segy file using the input filename as a framework\n",
    "            input_file=filename\n",
    "\n",
    "        output_file=savename + '.sgy'\n",
    "\n",
    "        copyfile(input_file, output_file)\n",
    "\n",
    "        with data_io.segyio.open( output_file, \"r+\" ) as src:\n",
    "            # iterate through each inline and update the values\n",
    "            i = 0\n",
    "            for ilno in src.ilines:\n",
    "                src.iline[ilno] = -1*(np.ones((src.iline[ilno].shape),dtype = np.float32))\n",
    "\n",
    "                if src.ilines[section_edge[0]] <= ilno <= src.ilines[section_edge[1]]:\n",
    "                    line = src.iline[ilno]\n",
    "                    line[section_edge[2]:section_edge[3]+1,section_edge[4]:section_edge[5]+1] = prediction[i,:,:,class_row]\n",
    "                    src.iline[ilno]=line\n",
    "                    i += 1\n",
    "\n",
    "        # Save the csv(ixz) file\n",
    "        csv_struct(inp_numpy = prediction[:,:,:,class_row],\n",
    "                   spec_obj = seis_obj,\n",
    "                   section = section_edge,\n",
    "                   inp_res = np.float32,\n",
    "                   save = True,\n",
    "                   savename = (savename + '.ixz'))\n",
    "\n",
    "        # Print to the user that the function has finished saving\n",
    "        print('Prediction saved.')\n",
    "\n",
    "    # Return the prediction array\n",
    "    return prediction    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ---- Functions for visualizing the predictions from the program ----\n",
    "# Make a plotting function for plotting the features\n",
    "def plotNNpred(pred,im_per_line,line_num,section):\n",
    "    # pred: 4D-numpy array with the features in the 4th dimension\n",
    "    # im_per_line: How many sub plot images to have in each row of the display\n",
    "    # line_num: what xline to use as a reference\n",
    "    # section: the section that was used for prediction\n",
    "\n",
    "    # Define some initial parameters, like the number of features and plot size, etc.\n",
    "    features = pred.shape[3]\n",
    "    plt.figure(2, figsize=(20,20))\n",
    "    n_columns = im_per_line\n",
    "    n_rows = math.ceil(features / n_columns) + 1\n",
    "\n",
    "    # Itterate through the sub-plots and fill them with the features, do some simple formatting\n",
    "    for i in range(features):\n",
    "        plt.subplot(n_rows, n_columns, i+1)\n",
    "        plt.title('Feature ' + str(i+1))\n",
    "        plt.imshow(pred[:,line_num-1,:,i].T, interpolation=\"nearest\", cmap=\"rainbow\",\\\n",
    "                   extent=[section[0],section[1],-section[5],-section[4]])\n",
    "        plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make and visualize the predicted data\n",
    "def visualization(filename,inp_seis,seis_obj,keras_model,cube_incr,section_edge,xline_ref,num_classes,\\\n",
    "                  inp_res=np.float64,sect_form = None,save_pred = False, save_file = 'default_write', \\\n",
    "                  pred_batch = 1,show_feature = False, show_prob = True):\n",
    "    # filename: filename of the segy-cube to be imported (necessary for copying the segy-frame before writing a new segy)\n",
    "    # inp_seis: a 3D numpy array that holds the input seismic cube\n",
    "    # seis_obj: Object returned from the segy_decomp function\n",
    "    # keras_model: keras model that has been trained previously\n",
    "    # cube_incr: number of increments included in each direction from the example to make a mini-cube\n",
    "    # section_edge: edge locations of the sub-section; either index or (min. inline, max. inline, min. xline, max xline, min z, max z)\n",
    "    # xline_ref: reference crossline from the original seismic cube to be plotted with the prediction (must be within section)\n",
    "    # num_classes: number of classes to be predicted\n",
    "    # inp_res: input resolution, the formatting of the seismic cube (could be changed to 8-bit data)\n",
    "    # sect_form: formatting of the section edges (if 'segy' we have to convert iline,xline,time to indexes)\n",
    "    # save_pred: whether or not to save the prediction as a segy, numpy and csv(ixz) file.\n",
    "    # save_file: name of the files to be saved (extensions are added automatically)\n",
    "    # pred_batch: number of traces to predict on at a time\n",
    "    # show_features: whether or not to get the features or the classes\n",
    "    # show_prob: if the user wants to get out probabilities or classifications\n",
    "\n",
    "\n",
    "\n",
    "    # Adjust the section numbering and reference xline from inline-xline-time to index if this is given in segy format\n",
    "    if sect_form == 'segy':\n",
    "        section_edge[0] = (section_edge[0] - seis_obj.inl_start)//seis_obj.inl_step\n",
    "        section_edge[1] = (section_edge[1] - seis_obj.inl_start)//seis_obj.inl_step\n",
    "        #\n",
    "        section_edge[2] = (section_edge[2] - seis_obj.xl_start)//seis_obj.xl_step\n",
    "        section_edge[3] = (section_edge[3] - seis_obj.xl_start)//seis_obj.xl_step\n",
    "        #\n",
    "        section_edge[4] = (section_edge[4] - seis_obj.t_start)//seis_obj.t_step\n",
    "        section_edge[5] = (section_edge[5] - seis_obj.t_start)//seis_obj.t_step\n",
    "        #\n",
    "        xline_ref = (xline_ref - seis_obj.xl_start)//seis_obj.xl_step\n",
    "        \n",
    "    # after inline/xline conversion\n",
    "    print(' Partial section geometry: ')\n",
    "    print('ils=', section_edge[0], 'ile=', section_edge[1])\n",
    "    print('xls=', section_edge[2], 'xle=', section_edge[3])\n",
    "    print('zls=', section_edge[4], 'zle=', section_edge[5])\n",
    "    print('xline_ref={}\\n'.format(xline_ref))\n",
    "\n",
    "    #\n",
    "    assert xline_ref > cube_incr and xline_ref < inp_seis.shape[1]-cube_incr, \" xline is too small or too big\"\n",
    "    \n",
    "    # \n",
    "    print(' inp_seis shape=', inp_seis.shape, ' cube_incr=', cube_incr)\n",
    "    \n",
    "    # adjustment \n",
    "    if section_edge[0] < cube_incr:\n",
    "        section_edge[0] = cube_incr\n",
    "    if section_edge[2] < cube_incr:\n",
    "        section_edge[2] = cube_incr\n",
    "    if section_edge[4] < cube_incr:\n",
    "        section_edge[4] = cube_incr\n",
    "    #\n",
    "    if section_edge[1] >= inp_seis.shape[0] - cube_incr:\n",
    "        section_edge[1] = inp_seis.shape[0] - cube_incr -1\n",
    "    if section_edge[3] >= inp_seis.shape[1] - cube_incr:\n",
    "        section_edge[3] = inp_seis.shape[1] - cube_incr -1\n",
    "    if section_edge[5] >= inp_seis.shape[2] - cube_incr:\n",
    "        section_edge[5] = inp_seis.shape[2] - cube_incr -1\n",
    "        \n",
    "    # after inline/xline conversion\n",
    "    print(' After adjustment, partial section geometry: ')\n",
    "    print('ils=', section_edge[0], 'ile=', section_edge[1])\n",
    "    print('xls=', section_edge[2], 'xle=', section_edge[3])\n",
    "    print('zls=', section_edge[4], 'zle=', section_edge[5])\n",
    "    \n",
    "    # Make the prediction\n",
    "    pred = predicting(filename=filename,\n",
    "                      inp_seis=inp_seis,\n",
    "                      seis_obj=seis_obj,\n",
    "                      keras_model=keras_model,\n",
    "                      cube_incr=cube_incr,\n",
    "                      num_classes = num_classes,\n",
    "                      inp_res = inp_res,\n",
    "                      mode='section',\n",
    "                      section=section_edge,\n",
    "                      line_num=xline_ref,\n",
    "                      print_segy=save_pred,\n",
    "                      savename=save_file,\n",
    "                      pred_batch = pred_batch,\n",
    "                      show_features=show_feature,\n",
    "                      layer_name='attribute_layer',\n",
    "                      show_prob = show_prob)\n",
    "\n",
    "    # Define some parameters used for getting nice plots(range of c-axis, and which row to show in the prediction)\n",
    "    features = pred.shape[2]\n",
    "    if show_prob:\n",
    "        class_row = 1\n",
    "        c_max = 1\n",
    "    else:\n",
    "        class_row = 0\n",
    "        c_max = num_classes-1\n",
    "\n",
    "    # Visualize the results from the prediction, either with features or classes/probabilities\n",
    "    if show_feature:\n",
    "        # Make the figure object/handle and plot the reference xline\n",
    "        plt.figure(1, figsize=(15,15))\n",
    "        plt.title('x-line')\n",
    "        plt.imshow(inp_seis[cube_incr:-cube_incr,xline_ref,cube_incr:-cube_incr].T,interpolation=\"nearest\",\\\n",
    "                   cmap=\"gray\",extent=[cube_incr,-cube_incr+len(inp_seis),cube_incr-len(inp_seis[0,0]),-cube_incr])\n",
    "\n",
    "        # Plot all the features and show the figures\n",
    "        plotNNpred(pred,5,xline_ref-section_edge[2]+1,section_edge)\n",
    "        plt.show()\n",
    "\n",
    "    else:\n",
    "        # Make the figure object/handle and plot the reference xline\n",
    "        plt.figure(1, figsize=(15,15))\n",
    "        gs = gridspec.GridSpec(1, 2, width_ratios=[3, 1])\n",
    "        plt.subplot(gs[0])\n",
    "        plt.title('x-line: {}'.format(xline_ref))\n",
    "        plt.imshow(inp_seis[cube_incr:-cube_incr,xline_ref,cube_incr:-cube_incr, 0].T,interpolation=\"nearest\",\\\n",
    "           cmap=\"gray\",extent=[cube_incr,-cube_incr+len(inp_seis),cube_incr-len(inp_seis[0,0]),-cube_incr])\n",
    "        plt.colorbar()\n",
    "\n",
    "        # Plot the probability/classification and show the figures\n",
    "        plt.subplot(gs[1])\n",
    "        plt.title('classification/probability of 1,x-line: {}'.format(xline_ref))\n",
    "        pred0 = np.squeeze(pred[:, :, :,class_row])\n",
    "        print(' prediction shape={}-{}-{}-{}'.format(pred.shape[0], pred.shape[1], \n",
    "                                                     pred.shape[2], pred.shape[3]))\n",
    "        plt.imshow(pred0.T,interpolation=\"nearest\", cmap=\"gist_rainbow\", clim=(0.0, c_max))\n",
    "                        \n",
    "        plt.colorbar()\n",
    "        plt.show()\n",
    "\n",
    "    # Return the predicted numpy cube\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rough function to show more detailed plots of the predictions in python for QC before going to Petrel\n",
    "def show_details(filename,cube_incr,predic,inline,inl_start,xline,xl_start,\\\n",
    "                 slice_number,slice_incr,inp_format=np.float64,show_prob = True,num_classes = 2):\n",
    "    # filename: filename of the segy-cube to be imported (necessary for copying the segy-frame before writing a new segy)\n",
    "    # cube_incr: number of increments included in each direction from the example to make a mini-cube\n",
    "    # predic: numpy cube holding the prediction\n",
    "    # inline: inline number to center our visualization on\n",
    "    # inl_start: index of the first inline in the prediction\n",
    "    # xline: xline number to center our visualization on\n",
    "    # xl_start: index of the first xline in the prediction\n",
    "    # slice_number: depth slice number to center our visualization on\n",
    "    # slice_incr: increments to take in depth between each plot\n",
    "    # inp_format: input resolution, the formatting of the seismic cube (could be changed to 8-bit data)\n",
    "    # show_prob: if the user wants to get out probabilities or classifications\n",
    "    # num_classes: number of classes that was predicted\n",
    "\n",
    "\n",
    "    # Read out the reference segy object\n",
    "    segy_obj = data_io.segy_decomp(segy_file = filename,\n",
    "                           plot_data = False,\n",
    "                           read_direc = 'xline',\n",
    "                           inp_res = inp_format)\n",
    "\n",
    "    # Get the numpy cube from the reference segy object\n",
    "    inp_seis = segy_obj.data\n",
    "\n",
    "    # define some parameters used for getting nice plots(range of c-axis, and which row to show in the prediction)\n",
    "    if show_prob:\n",
    "        class_row = 1\n",
    "        c_max = 1\n",
    "    else:\n",
    "        class_row = 0\n",
    "        c_max = num_classes-1\n",
    "\n",
    "    # Make the figure object/handle and plot the reference xline\n",
    "    plt.figure(1, figsize=(20,15))\n",
    "    plt.subplot(1, 8, 1)\n",
    "    plt.title('xline: ' + str(xline))\n",
    "    plt.imshow(inp_seis[inline-cube_incr:inline+cube_incr,xline,cube_incr:-cube_incr].T,interpolation=\"nearest\", cmap=\"gray\")\n",
    "    plt.colorbar()\n",
    "\n",
    "    # Plot the prediciton for the reference xline along with 3 increments in each direction\n",
    "    plt.subplot(1, 8, 2)\n",
    "    plt.title('xline - 3')\n",
    "    plt.imshow(predic[:,xline-xl_start - 3,:,class_row].T,interpolation=\"nearest\", cmap=\"gist_rainbow\", clim=(0.0, c_max))\n",
    "    \n",
    "    plt.subplot(1, 8, 3)\n",
    "    plt.title('xline')\n",
    "    plt.imshow(predic[:,xline-xl_start,:,class_row].T,interpolation=\"nearest\", cmap=\"gist_rainbow\", clim=(0.0, c_max))\n",
    "\n",
    "    plt.subplot(1, 8, 4)\n",
    "    plt.title('xline + 3')\n",
    "    plt.imshow(predic[:,xline-xl_start + 3,:,class_row].T,interpolation=\"nearest\", cmap=\"gist_rainbow\", clim=(0.0, c_max))\n",
    "    plt.colorbar()\n",
    "    \n",
    "    # Plot the reference inline\n",
    "    plt.subplot(1, 8, 1+4)\n",
    "    plt.title('inline: ' + str(inline))\n",
    "    plt.imshow(inp_seis[inline,xline-cube_incr:xline+cube_incr,cube_incr:-cube_incr].T,interpolation=\"nearest\", cmap=\"gray\")\n",
    "    plt.colorbar()\n",
    "\n",
    "    # Plot the prediciton for the reference inline along with 3 increments in each direction\n",
    "    plt.subplot(1, 8, 2+4)\n",
    "    plt.title('inline - 3')\n",
    "    plt.imshow(predic[inline-inl_start-3,:,:,class_row].T,interpolation=\"nearest\", cmap=\"gist_rainbow\", clim=(0.0, c_max))\n",
    "\n",
    "    plt.subplot(1, 8, 3+4)\n",
    "    plt.title('inline')\n",
    "    plt.imshow(predic[inline-inl_start,:,:,class_row].T,interpolation=\"nearest\", cmap=\"gist_rainbow\", clim=(0.0, c_max))\n",
    "\n",
    "    plt.subplot(1, 8, 4+4)\n",
    "    plt.title('inline + 3')\n",
    "    plt.imshow(predic[inline-inl_start+3,:,:,class_row].T,interpolation=\"nearest\", cmap=\"gist_rainbow\", clim=(0.0, c_max))\n",
    "    plt.colorbar()\n",
    "\n",
    "    # Make a new figure object/handle and plot 3 reference depth slices\n",
    "    plt.figure(2, figsize=(20,5))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.title('slice - ' + str(slice_incr))\n",
    "    plt.imshow(inp_seis[inline-cube_incr:inline+cube_incr,xline-cube_incr:xline+cube_incr,cube_incr+slice_number-slice_incr].T,\\\n",
    "               interpolation=\"nearest\", cmap=\"gray\")\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.title('slice: ' + str(slice_number))\n",
    "    plt.imshow(inp_seis[inline-cube_incr:inline+cube_incr,xline-cube_incr:xline+cube_incr,cube_incr+slice_number].T,\\\n",
    "               interpolation=\"nearest\", cmap=\"gray\")\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.title('slice + ' + str(slice_incr))\n",
    "    plt.imshow(inp_seis[inline-cube_incr:inline+cube_incr,xline-cube_incr:xline+cube_incr,cube_incr+slice_number+slice_incr].T,\\\n",
    "               interpolation=\"nearest\", cmap=\"gray\")\n",
    "    plt.colorbar()\n",
    "\n",
    "    # Make a new figure object/handle and plot the 3 corresponding predicted depth slices\n",
    "    plt.figure(3, figsize=(20,5))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.title('slice - ' + str(slice_incr))\n",
    "    plt.imshow(predic[:,:,slice_number-slice_incr,class_row].T,interpolation=\"nearest\", cmap=\"gist_rainbow\", clim=(0.0, c_max))\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.title('slice: ' + str(slice_number))\n",
    "    plt.imshow(predic[:,:,slice_number,class_row].T,interpolation=\"nearest\", cmap=\"gist_rainbow\", clim=(0.0, c_max))\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.title('slice + ' + str(slice_incr))\n",
    "    plt.imshow(predic[:,:,slice_number+slice_incr,class_row].T,interpolation=\"nearest\", cmap=\"gist_rainbow\", clim=(0.0, c_max))\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ---- MASTER/MAIN function ----\n",
    "# Make an overall master function that takes inn some basic parameters,\n",
    "# trains, predicts, and visualizes the results from a model\n",
    "def master(segy_filename,inp_format,cube_incr,train_dict={},pred_dict={},mode = 'full'):\n",
    "    # segy_filename: filename of the segy-cube to be imported (necessary for copying the segy-frame before writing a new segy)\n",
    "    # inp_format: input resolution, the formatting of the seismic cube (could be changed to 8-bit data)\n",
    "    # cube_incr: number of increments included in each direction from the example to make a mini-cube\n",
    "    # train_dict: Training parameters packaged as a Python dictionary\n",
    "    # pred_dict: Prediciton parameters packaged as a Python dictionary\n",
    "    # mode: Do we want to train a model('train'), predict using an external model('predict'), or train a model and predict using it('full')\n",
    "\n",
    "    # Implement more than one segy-cube if the input segy_filename is a list\n",
    "    if type(segy_filename) is str or (type(segy_filename) is list and len(segy_filename) == 1):\n",
    "        # Check if the filename needs to be retrieved from a list\n",
    "        if type(segy_filename) is list:\n",
    "            segy_filename = segy_filename[0]\n",
    "\n",
    "        # Make a master segy object\n",
    "        segy_obj = data_io.segy_decomp(segy_file = segy_filename,\n",
    "                               plot_data = False,\n",
    "                               read_direc = 'full',\n",
    "                               inp_res = inp_format)\n",
    "\n",
    "        # Define how many segy-cubes we're dealing with\n",
    "        segy_obj.cube_num = 1\n",
    "        segy_obj.data = np.expand_dims(segy_obj.data, axis = 4)\n",
    "\n",
    "    elif type(segy_filename) is list:\n",
    "        # start an iterator\n",
    "        i = 0\n",
    "\n",
    "        # iterate through the list of cube names and store them in a masterobject\n",
    "        for filename in segy_filename:\n",
    "            # Make a master segy object\n",
    "            if i == 0:\n",
    "                segy_obj = data_io.segy_decomp(segy_file = filename,\n",
    "                                       plot_data = False,\n",
    "                                       read_direc = 'full',\n",
    "                                       inp_res = inp_format)\n",
    "\n",
    "                # Define how many segy-cubes we're dealing with\n",
    "                segy_obj.cube_num = len(segy_filename)\n",
    "\n",
    "                # Reshape and preallocate the numpy-array for the rest of the cubes\n",
    "                print('Starting restructuring to 4D arrays')\n",
    "                ovr_data = np.empty((list(segy_obj.data.shape) + [len(segy_filename)]))\n",
    "                ovr_data[:,:,:,i] = segy_obj.data\n",
    "                segy_obj.data = ovr_data\n",
    "                ovr_data = None\n",
    "                print('Finished restructuring to 4D arrays')\n",
    "            else:\n",
    "                # Add another cube to the numpy-array\n",
    "                segy_obj.data[:,:,:,i] = data_io.segy_adder(segy_file = filename,\n",
    "                                                    inp_cube = segy_obj.data,\n",
    "                                                    read_direc = 'full',\n",
    "                                                    inp_res = inp_format)\n",
    "            # Increase the itterator\n",
    "            i+=1\n",
    "    else:\n",
    "        print('The input filename needs to be a string, or a list of strings')\n",
    "\n",
    "\n",
    "    print('Finished unpaking and restructuring the numpy array')\n",
    "\n",
    "\n",
    "    # Are we going to perform training?\n",
    "    if mode == 'train' or mode == 'full':\n",
    "        # Unpack the dictionary of training parameters\n",
    "        label_list = train_dict['files']\n",
    "        num_bunch = train_dict['num_tot_iterations']\n",
    "        num_epochs = train_dict['epochs']\n",
    "        num_examples = train_dict['num_train_ex']\n",
    "        batch_size = train_dict['batch_size']\n",
    "        opt_patience = train_dict['opt_patience']\n",
    "        data_augmentation = train_dict['data_augmentation']\n",
    "        write_out = train_dict['save_model']\n",
    "        write_location = train_dict['save_location']\n",
    "\n",
    "        # If there is a model given in the prediction dictionary continue training on this model\n",
    "        if 'keras_model' in pred_dict:\n",
    "            keras_model = pred_dict['keras_model']\n",
    "        else:\n",
    "            keras_model = None\n",
    "\n",
    "        # Print out an initial statement to confirm the parameters(QC)\n",
    "        print('num full iterations:', num_bunch)\n",
    "        print('num epochs:',num_epochs)\n",
    "        print('num examples per epoch:',num_examples)\n",
    "        print('batch size:',batch_size)\n",
    "        print('optimizer patience:',opt_patience)\n",
    "\n",
    "\n",
    "        # Make the list of class data\n",
    "        print('Making class-adresses')\n",
    "        class_array = data_io.convert(file_list = label_list,\n",
    "                              save = False,\n",
    "                              savename = None,\n",
    "                              ex_adjust = True)\n",
    "\n",
    "        print('Finished making class-adresses')\n",
    "\n",
    "        # Time the training process\n",
    "        start_train_time = time.time()\n",
    "\n",
    "        # Train a new model/further train the uploaded model and store the result as the model output\n",
    "        model = train_model(segy_obj = segy_obj,\n",
    "                            class_array = class_array,\n",
    "                            num_classes = len(label_list),\n",
    "                            cube_incr = cube_incr,\n",
    "                            inp_res = inp_format,\n",
    "                            num_bunch = num_bunch,\n",
    "                            num_epochs = num_epochs,\n",
    "                            num_examples = num_examples,\n",
    "                            batch_size = batch_size,\n",
    "                            opt_patience = opt_patience,\n",
    "                            data_augmentation = data_augmentation,\n",
    "                            num_channels = segy_obj.cube_num,\n",
    "                            keras_model = keras_model,\n",
    "                            write_out = write_out,\n",
    "                            write_location = write_location)\n",
    "\n",
    "        # Time the training process\n",
    "        end_train_time = time.time()\n",
    "        train_time = end_train_time-start_train_time # seconds\n",
    "\n",
    "        # print to the user the total time spent training\n",
    "        if train_time <= 300:\n",
    "            print('Total time elapsed during training:',train_time, ' sec.')\n",
    "        elif 300 < train_time <= 60*60:\n",
    "            minutes = train_time//60\n",
    "            seconds = (train_time%60)*(60/100)\n",
    "            print('Total time elapsed during training:',minutes,' min., ',seconds,' sec.')\n",
    "        elif 60*60 < train_time <= 60*60*24:\n",
    "            hours = train_time//(60*60)\n",
    "            minutes = (train_time%(60*60))*(1/60)*(60/100)\n",
    "            print('Total time elapsed during training:',hours,' hrs., ',minutes,' min., ')\n",
    "        else:\n",
    "            days = train_time//(24*60*60)\n",
    "            hours = (train_time%(24*60*60))*(1/60)*((1/60))*(24/100)\n",
    "            print('Total time elapsed during training:',days,' days, ',hours,' hrs., ')\n",
    "\n",
    "    elif mode == 'predict':\n",
    "        # If we aren't performing any training\n",
    "        print('Using uploaded model for prediction')\n",
    "    else:\n",
    "        print('Invalid mode! Accepted inputs are ''train'', ''predict'', or ''full''')\n",
    "        return None\n",
    "\n",
    "    # Are we going to perform prediction?\n",
    "    if mode == 'predict' or mode == 'full':\n",
    "        # Let the user know if we have made new computations on the model used for prediction\n",
    "        if mode == 'full':\n",
    "            print('Using the newly computed model for prediction')\n",
    "        else:\n",
    "            model  = pred_dict['keras_model']\n",
    "\n",
    "        # Unpack the prediction dictionary\n",
    "        section_edge  = pred_dict['section_edge']  # np.asarray([339, 339, xls, xle, ts, te])\n",
    "        xline_ref = pred_dict['xline']\n",
    "        num_classes = pred_dict['num_class']\n",
    "        sect_form = pred_dict['cord_syst']            # 'segy'\n",
    "        show_feature  = pred_dict['show_feature']\n",
    "        save_pred = pred_dict['save_pred']\n",
    "        save_loc = pred_dict['save_location']\n",
    "        pred_batch = pred_dict['pred_batch']\n",
    "        prob = pred_dict['pred_prob']\n",
    "\n",
    "        # Time the prediction process\n",
    "        start_pred_time = time.time()\n",
    "\n",
    "        # Make a prediction on the master segy object using the desired model, and plot the results\n",
    "        pred = visualization(filename = segy_filename,\n",
    "                             inp_seis = segy_obj.data,\n",
    "                             seis_obj = segy_obj,\n",
    "                             keras_model = model,\n",
    "                             cube_incr = cube_incr,\n",
    "                             section_edge = section_edge,\n",
    "                             xline_ref = xline_ref,\n",
    "                             num_classes = num_classes,\n",
    "                             inp_res = inp_format,\n",
    "                             sect_form = sect_form,\n",
    "                             save_pred = save_pred,\n",
    "                             save_file = save_loc,\n",
    "                             pred_batch = pred_batch,\n",
    "                             show_feature = show_feature,\n",
    "                             show_prob = prob)\n",
    "\n",
    "        # Print the time taken for the prediction\n",
    "        end_pred_time = time.time()\n",
    "        pred_time = end_pred_time-start_pred_time # seconds\n",
    "\n",
    "        # print to the user the total time spent training\n",
    "        if pred_time <= 300:\n",
    "            print('Total time elapsed during prediction:',pred_time, ' sec.')\n",
    "        elif 300 < pred_time <= 60*60:\n",
    "            minutes = pred_time//60\n",
    "            seconds = (pred_time%60)*(60/100)\n",
    "            print('Total time elapsed during prediction:',minutes,' min., ',seconds,' sec.')\n",
    "        elif 60*60 < pred_time <= 60*60*24:\n",
    "            hours = pred_time//(60*60)\n",
    "            minutes = (pred_time%(60*60))*(1/60)*(60/100)\n",
    "            print('Total time elapsed during prediction:',hours,' hrs., ',minutes,' min., ')\n",
    "        else:\n",
    "            days = pred_time//(24*60*60)\n",
    "            hours = (pred_time%(24*60*60))*(1/60)*((1/60))*(24/100)\n",
    "            print('Total time elapsed during prediction:',days,' days, ',hours,' hrs., ')\n",
    "\n",
    "    else:\n",
    "        # Make an empty variable for the prediction output\n",
    "        pred = None\n",
    "\n",
    "    # Return the new model and/or prediction as an output dictionary\n",
    "    output = {\n",
    "        'model' : model,\n",
    "        'pred' : pred\n",
    "    }\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting SEG-Y decompressor\n",
      " SEGY inline/xline/t geometry:\n",
      " ils=100, ile=750, ili=1, ilen=651\n",
      "\n",
      " xls=300, xle=1250, xli=1, xlen=951\n",
      "\n",
      " ts=4, te=1848, ti=4\n",
      "\n",
      "Finished using the SEG-Y decompressor\n",
      "Finished unpaking and restructuring the numpy array\n",
      "num full iterations: 25\n",
      "num epochs: 10\n",
      "num examples per epoch: 20000\n",
      "batch size: 32\n",
      "optimizer patience: 10\n",
      "Making class-adresses\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/wgdisk/st0008/hzh/workspace/env_all/lib/python3.6/site-packages/ipykernel_launcher.py:26: DeprecationWarning: Both axis > a.ndim and axis < -a.ndim - 1 are deprecated and will raise an AxisError in the future.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished making class-adresses\n",
      "Iteration number: 1 / 25\n",
      "Starting training data creation:\n",
      "Defining the buffer zone:\n",
      "(inl_min, inl_max, xl_min, xl_max, t_min, t_max)\n",
      "( 132 , 718 , 332 , 1218 , 132 , 1720 )\n",
      "( 32 , 918 , 32 , 429 )\n",
      "Finished creating 20000 examples!\n",
      "Not using data augmentation.\n",
      "Train on 16000 samples, validate on 4000 samples\n",
      "Epoch 1/10\n",
      "16000/16000 [==============================] - 18s 1ms/step - loss: 0.1623 - acc: 0.9777 - val_loss: 0.0505 - val_acc: 0.9915\n",
      "Epoch 2/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0920 - acc: 0.9867 - val_loss: 0.0162 - val_acc: 0.9978\n",
      "Epoch 3/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0644 - acc: 0.9894 - val_loss: 0.0188 - val_acc: 0.9975\n",
      "Epoch 4/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0640 - acc: 0.9899 - val_loss: 0.0174 - val_acc: 0.9978\n",
      "Epoch 5/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0616 - acc: 0.9909 - val_loss: 0.0178 - val_acc: 0.9978\n",
      "Epoch 6/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0566 - acc: 0.9906 - val_loss: 0.0177 - val_acc: 0.9978\n",
      "Epoch 7/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0668 - acc: 0.9896 - val_loss: 0.0180 - val_acc: 0.9975\n",
      "Epoch 8/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0671 - acc: 0.9894 - val_loss: 0.0178 - val_acc: 0.9978\n",
      "Epoch 9/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0644 - acc: 0.9896 - val_loss: 0.0178 - val_acc: 0.9978\n",
      "Epoch 10/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0609 - acc: 0.9903 - val_loss: 0.0182 - val_acc: 0.9975\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv_layer1 (Conv2D)         (None, 17, 17, 50)        1300      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 17, 17, 50)        200       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 17, 17, 50)        0         \n",
      "_________________________________________________________________\n",
      "conv_layer2 (Conv2D)         (None, 9, 9, 50)          22550     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 9, 9, 50)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 9, 9, 50)          200       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 9, 9, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv_layer3 (Conv2D)         (None, 5, 5, 50)          22550     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 5, 5, 50)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 5, 5, 50)          200       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 5, 5, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv_layer4 (Conv2D)         (None, 3, 3, 50)          22550     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 3, 3, 50)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 3, 3, 50)          200       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 3, 3, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv_layer5 (Conv2D)         (None, 2, 2, 50)          22550     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_layer1 (Dense)         (None, 50)                10050     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 50)                200       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "attribute_layer (Dense)      (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "pre-softmax_layer (Dense)    (None, 9)                 99        \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 9)                 36        \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 9)                 0         \n",
      "=================================================================\n",
      "Total params: 103,235\n",
      "Trainable params: 102,697\n",
      "Non-trainable params: 538\n",
      "_________________________________________________________________\n",
      "None\n",
      "Approximate time remaining of the training: 1.0  hrs.,  5.085138359069824  min., \n",
      "Iteration number: 2 / 25\n",
      "Starting training data creation:\n",
      "Defining the buffer zone:\n",
      "(inl_min, inl_max, xl_min, xl_max, t_min, t_max)\n",
      "( 132 , 718 , 332 , 1218 , 132 , 1720 )\n",
      "( 32 , 918 , 32 , 429 )\n",
      "Finished creating 20000 examples!\n",
      "Not using data augmentation.\n",
      "Train on 16000 samples, validate on 4000 samples\n",
      "Epoch 1/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.1534 - acc: 0.9784 - val_loss: 0.1583 - val_acc: 0.9820\n",
      "Epoch 2/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0790 - acc: 0.9888 - val_loss: 0.0266 - val_acc: 0.9980\n",
      "Epoch 3/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0662 - acc: 0.9892 - val_loss: 0.0258 - val_acc: 0.9980\n",
      "Epoch 4/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0568 - acc: 0.9915 - val_loss: 0.0249 - val_acc: 0.9980\n",
      "Epoch 5/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0737 - acc: 0.9884 - val_loss: 0.0257 - val_acc: 0.9980\n",
      "Epoch 6/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0672 - acc: 0.9893 - val_loss: 0.0260 - val_acc: 0.9980\n",
      "Epoch 7/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0587 - acc: 0.9907 - val_loss: 0.0255 - val_acc: 0.9980\n",
      "Epoch 8/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0786 - acc: 0.9890 - val_loss: 0.0254 - val_acc: 0.9980\n",
      "Epoch 9/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0860 - acc: 0.9887 - val_loss: 0.0260 - val_acc: 0.9980\n",
      "Epoch 10/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0662 - acc: 0.9907 - val_loss: 0.0260 - val_acc: 0.9980\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv_layer1 (Conv2D)         (None, 17, 17, 50)        1300      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 17, 17, 50)        200       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 17, 17, 50)        0         \n",
      "_________________________________________________________________\n",
      "conv_layer2 (Conv2D)         (None, 9, 9, 50)          22550     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 9, 9, 50)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 9, 9, 50)          200       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 9, 9, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv_layer3 (Conv2D)         (None, 5, 5, 50)          22550     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 5, 5, 50)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 5, 5, 50)          200       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 5, 5, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv_layer4 (Conv2D)         (None, 3, 3, 50)          22550     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 3, 3, 50)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 3, 3, 50)          200       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 3, 3, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv_layer5 (Conv2D)         (None, 2, 2, 50)          22550     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_layer1 (Dense)         (None, 50)                10050     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 50)                200       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "attribute_layer (Dense)      (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "pre-softmax_layer (Dense)    (None, 9)                 99        \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 9)                 36        \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 9)                 0         \n",
      "=================================================================\n",
      "Total params: 103,235\n",
      "Trainable params: 102,697\n",
      "Non-trainable params: 538\n",
      "_________________________________________________________________\n",
      "None\n",
      "Approximate time remaining of the training: 1.0  hrs.,  3.373257594108581  min., \n",
      "Iteration number: 3 / 25\n",
      "Starting training data creation:\n",
      "Defining the buffer zone:\n",
      "(inl_min, inl_max, xl_min, xl_max, t_min, t_max)\n",
      "( 132 , 718 , 332 , 1218 , 132 , 1720 )\n",
      "( 32 , 918 , 32 , 429 )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating 20000 examples!\n",
      "Not using data augmentation.\n",
      "Train on 16000 samples, validate on 4000 samples\n",
      "Epoch 1/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.1846 - acc: 0.9758 - val_loss: 0.0696 - val_acc: 0.9888\n",
      "Epoch 2/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0798 - acc: 0.9892 - val_loss: 0.0198 - val_acc: 0.9978\n",
      "Epoch 3/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0821 - acc: 0.9888 - val_loss: 0.0167 - val_acc: 0.9978\n",
      "Epoch 4/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0799 - acc: 0.9892 - val_loss: 0.0173 - val_acc: 0.9975\n",
      "Epoch 5/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0720 - acc: 0.9893 - val_loss: 0.0176 - val_acc: 0.9978\n",
      "Epoch 6/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0810 - acc: 0.9886 - val_loss: 0.0161 - val_acc: 0.9978\n",
      "Epoch 7/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0680 - acc: 0.9905 - val_loss: 0.0167 - val_acc: 0.9978\n",
      "Epoch 8/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0661 - acc: 0.9908 - val_loss: 0.0169 - val_acc: 0.9978\n",
      "Epoch 9/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0728 - acc: 0.9899 - val_loss: 0.0164 - val_acc: 0.9980\n",
      "Epoch 10/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0881 - acc: 0.9882 - val_loss: 0.0169 - val_acc: 0.9978\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv_layer1 (Conv2D)         (None, 17, 17, 50)        1300      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 17, 17, 50)        200       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 17, 17, 50)        0         \n",
      "_________________________________________________________________\n",
      "conv_layer2 (Conv2D)         (None, 9, 9, 50)          22550     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 9, 9, 50)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 9, 9, 50)          200       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 9, 9, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv_layer3 (Conv2D)         (None, 5, 5, 50)          22550     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 5, 5, 50)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 5, 5, 50)          200       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 5, 5, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv_layer4 (Conv2D)         (None, 3, 3, 50)          22550     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 3, 3, 50)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 3, 3, 50)          200       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 3, 3, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv_layer5 (Conv2D)         (None, 2, 2, 50)          22550     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_layer1 (Dense)         (None, 50)                10050     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 50)                200       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "attribute_layer (Dense)      (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "pre-softmax_layer (Dense)    (None, 9)                 99        \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 9)                 36        \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 9)                 0         \n",
      "=================================================================\n",
      "Total params: 103,235\n",
      "Trainable params: 102,697\n",
      "Non-trainable params: 538\n",
      "_________________________________________________________________\n",
      "None\n",
      "Approximate time remaining of the training: 1.0  hrs.,  1.661376829147339  min., \n",
      "Iteration number: 4 / 25\n",
      "Starting training data creation:\n",
      "Defining the buffer zone:\n",
      "(inl_min, inl_max, xl_min, xl_max, t_min, t_max)\n",
      "( 132 , 718 , 332 , 1218 , 132 , 1720 )\n",
      "( 32 , 918 , 32 , 429 )\n",
      "Finished creating 20000 examples!\n",
      "Not using data augmentation.\n",
      "Train on 16000 samples, validate on 4000 samples\n",
      "Epoch 1/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.1750 - acc: 0.9775 - val_loss: 0.0783 - val_acc: 0.9900\n",
      "Epoch 2/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0813 - acc: 0.9893 - val_loss: 0.0273 - val_acc: 0.9978\n",
      "Epoch 3/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0738 - acc: 0.9894 - val_loss: 0.0289 - val_acc: 0.9972\n",
      "Epoch 4/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0713 - acc: 0.9907 - val_loss: 0.0282 - val_acc: 0.9978\n",
      "Epoch 5/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0765 - acc: 0.9902 - val_loss: 0.0280 - val_acc: 0.9975\n",
      "Epoch 6/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0744 - acc: 0.9898 - val_loss: 0.0280 - val_acc: 0.9975\n",
      "Epoch 7/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0636 - acc: 0.9905 - val_loss: 0.0279 - val_acc: 0.9972\n",
      "Epoch 8/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0592 - acc: 0.9916 - val_loss: 0.0284 - val_acc: 0.9975\n",
      "Epoch 9/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0619 - acc: 0.9910 - val_loss: 0.0280 - val_acc: 0.9978\n",
      "Epoch 10/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0612 - acc: 0.9914 - val_loss: 0.0281 - val_acc: 0.9975\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv_layer1 (Conv2D)         (None, 17, 17, 50)        1300      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 17, 17, 50)        200       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 17, 17, 50)        0         \n",
      "_________________________________________________________________\n",
      "conv_layer2 (Conv2D)         (None, 9, 9, 50)          22550     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 9, 9, 50)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 9, 9, 50)          200       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 9, 9, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv_layer3 (Conv2D)         (None, 5, 5, 50)          22550     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 5, 5, 50)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 5, 5, 50)          200       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 5, 5, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv_layer4 (Conv2D)         (None, 3, 3, 50)          22550     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 3, 3, 50)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 3, 3, 50)          200       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 3, 3, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv_layer5 (Conv2D)         (None, 2, 2, 50)          22550     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_layer1 (Dense)         (None, 50)                10050     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 50)                200       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "attribute_layer (Dense)      (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "pre-softmax_layer (Dense)    (None, 9)                 99        \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 9)                 36        \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 9)                 0         \n",
      "=================================================================\n",
      "Total params: 103,235\n",
      "Trainable params: 102,697\n",
      "Non-trainable params: 538\n",
      "_________________________________________________________________\n",
      "None\n",
      "Approximate time remaining of the training: 59.0  min.,  32.96976385116577  sec.\n",
      "Iteration number: 5 / 25\n",
      "Starting training data creation:\n",
      "Defining the buffer zone:\n",
      "(inl_min, inl_max, xl_min, xl_max, t_min, t_max)\n",
      "( 132 , 718 , 332 , 1218 , 132 , 1720 )\n",
      "( 32 , 918 , 32 , 429 )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating 20000 examples!\n",
      "Not using data augmentation.\n",
      "Train on 16000 samples, validate on 4000 samples\n",
      "Epoch 1/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.1775 - acc: 0.9774 - val_loss: 0.0669 - val_acc: 0.9928\n",
      "Epoch 2/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0981 - acc: 0.9874 - val_loss: 0.0408 - val_acc: 0.9965\n",
      "Epoch 3/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0665 - acc: 0.9906 - val_loss: 0.0408 - val_acc: 0.9965\n",
      "Epoch 4/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0703 - acc: 0.9901 - val_loss: 0.0412 - val_acc: 0.9965\n",
      "Epoch 5/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0836 - acc: 0.9884 - val_loss: 0.0413 - val_acc: 0.9965\n",
      "Epoch 6/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0601 - acc: 0.9921 - val_loss: 0.0402 - val_acc: 0.9965\n",
      "Epoch 7/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0636 - acc: 0.9914 - val_loss: 0.0415 - val_acc: 0.9965\n",
      "Epoch 8/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0698 - acc: 0.9892 - val_loss: 0.0419 - val_acc: 0.9965\n",
      "Epoch 9/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0705 - acc: 0.9904 - val_loss: 0.0414 - val_acc: 0.9965\n",
      "Epoch 10/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0827 - acc: 0.9891 - val_loss: 0.0406 - val_acc: 0.9965\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv_layer1 (Conv2D)         (None, 17, 17, 50)        1300      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 17, 17, 50)        200       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 17, 17, 50)        0         \n",
      "_________________________________________________________________\n",
      "conv_layer2 (Conv2D)         (None, 9, 9, 50)          22550     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 9, 9, 50)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 9, 9, 50)          200       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 9, 9, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv_layer3 (Conv2D)         (None, 5, 5, 50)          22550     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 5, 5, 50)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 5, 5, 50)          200       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 5, 5, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv_layer4 (Conv2D)         (None, 3, 3, 50)          22550     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 3, 3, 50)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 3, 3, 50)          200       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 3, 3, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv_layer5 (Conv2D)         (None, 2, 2, 50)          22550     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_layer1 (Dense)         (None, 50)                10050     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 50)                200       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "attribute_layer (Dense)      (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "pre-softmax_layer (Dense)    (None, 9)                 99        \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 9)                 36        \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 9)                 0         \n",
      "=================================================================\n",
      "Total params: 103,235\n",
      "Trainable params: 102,697\n",
      "Non-trainable params: 538\n",
      "_________________________________________________________________\n",
      "None\n",
      "Approximate time remaining of the training: 57.0  min.,  2.256917953491211  sec.\n",
      "Iteration number: 6 / 25\n",
      "Starting training data creation:\n",
      "Defining the buffer zone:\n",
      "(inl_min, inl_max, xl_min, xl_max, t_min, t_max)\n",
      "( 132 , 718 , 332 , 1218 , 132 , 1720 )\n",
      "( 32 , 918 , 32 , 429 )\n",
      "Finished creating 20000 examples!\n",
      "Not using data augmentation.\n",
      "Train on 16000 samples, validate on 4000 samples\n",
      "Epoch 1/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.1348 - acc: 0.9809 - val_loss: 0.0787 - val_acc: 0.9910\n",
      "Epoch 2/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0901 - acc: 0.9874 - val_loss: 0.0141 - val_acc: 0.9980\n",
      "Epoch 3/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0554 - acc: 0.9916 - val_loss: 0.0177 - val_acc: 0.9975\n",
      "Epoch 4/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0508 - acc: 0.9922 - val_loss: 0.0167 - val_acc: 0.9978\n",
      "Epoch 5/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0603 - acc: 0.9904 - val_loss: 0.0175 - val_acc: 0.9978\n",
      "Epoch 6/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0538 - acc: 0.9918 - val_loss: 0.0183 - val_acc: 0.9978\n",
      "Epoch 7/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0523 - acc: 0.9921 - val_loss: 0.0175 - val_acc: 0.9975\n",
      "Epoch 8/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0476 - acc: 0.9921 - val_loss: 0.0180 - val_acc: 0.9978\n",
      "Epoch 9/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0483 - acc: 0.9922 - val_loss: 0.0173 - val_acc: 0.9978\n",
      "Epoch 10/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0570 - acc: 0.9912 - val_loss: 0.0184 - val_acc: 0.9975\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv_layer1 (Conv2D)         (None, 17, 17, 50)        1300      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 17, 17, 50)        200       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 17, 17, 50)        0         \n",
      "_________________________________________________________________\n",
      "conv_layer2 (Conv2D)         (None, 9, 9, 50)          22550     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 9, 9, 50)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 9, 9, 50)          200       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 9, 9, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv_layer3 (Conv2D)         (None, 5, 5, 50)          22550     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 5, 5, 50)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 5, 5, 50)          200       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 5, 5, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv_layer4 (Conv2D)         (None, 3, 3, 50)          22550     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 3, 3, 50)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 3, 3, 50)          200       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 3, 3, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv_layer5 (Conv2D)         (None, 2, 2, 50)          22550     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_layer1 (Dense)         (None, 50)                10050     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 50)                200       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "attribute_layer (Dense)      (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "pre-softmax_layer (Dense)    (None, 9)                 99        \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 9)                 36        \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 9)                 0         \n",
      "=================================================================\n",
      "Total params: 103,235\n",
      "Trainable params: 102,697\n",
      "Non-trainable params: 538\n",
      "_________________________________________________________________\n",
      "None\n",
      "Approximate time remaining of the training: 54.0  min.,  7.54407205581665  sec.\n",
      "Iteration number: 7 / 25\n",
      "Starting training data creation:\n",
      "Defining the buffer zone:\n",
      "(inl_min, inl_max, xl_min, xl_max, t_min, t_max)\n",
      "( 132 , 718 , 332 , 1218 , 132 , 1720 )\n",
      "( 32 , 918 , 32 , 429 )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating 20000 examples!\n",
      "Not using data augmentation.\n",
      "Train on 16000 samples, validate on 4000 samples\n",
      "Epoch 1/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.2072 - acc: 0.9749 - val_loss: 0.0534 - val_acc: 0.9938\n",
      "Epoch 2/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0967 - acc: 0.9871 - val_loss: 0.0219 - val_acc: 0.9980\n",
      "Epoch 3/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0824 - acc: 0.9905 - val_loss: 0.0226 - val_acc: 0.9980\n",
      "Epoch 4/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0721 - acc: 0.9894 - val_loss: 0.0229 - val_acc: 0.9980\n",
      "Epoch 5/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0799 - acc: 0.9891 - val_loss: 0.0234 - val_acc: 0.9980\n",
      "Epoch 6/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0678 - acc: 0.9899 - val_loss: 0.0232 - val_acc: 0.9980\n",
      "Epoch 7/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0601 - acc: 0.9915 - val_loss: 0.0234 - val_acc: 0.9980\n",
      "Epoch 8/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0705 - acc: 0.9902 - val_loss: 0.0230 - val_acc: 0.9980\n",
      "Epoch 9/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0720 - acc: 0.9898 - val_loss: 0.0231 - val_acc: 0.9980\n",
      "Epoch 10/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0767 - acc: 0.9897 - val_loss: 0.0233 - val_acc: 0.9980\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv_layer1 (Conv2D)         (None, 17, 17, 50)        1300      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 17, 17, 50)        200       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 17, 17, 50)        0         \n",
      "_________________________________________________________________\n",
      "conv_layer2 (Conv2D)         (None, 9, 9, 50)          22550     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 9, 9, 50)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 9, 9, 50)          200       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 9, 9, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv_layer3 (Conv2D)         (None, 5, 5, 50)          22550     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 5, 5, 50)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 5, 5, 50)          200       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 5, 5, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv_layer4 (Conv2D)         (None, 3, 3, 50)          22550     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 3, 3, 50)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 3, 3, 50)          200       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 3, 3, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv_layer5 (Conv2D)         (None, 2, 2, 50)          22550     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_layer1 (Dense)         (None, 50)                10050     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 50)                200       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "attribute_layer (Dense)      (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "pre-softmax_layer (Dense)    (None, 9)                 99        \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 9)                 36        \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 9)                 0         \n",
      "=================================================================\n",
      "Total params: 103,235\n",
      "Trainable params: 102,697\n",
      "Non-trainable params: 538\n",
      "_________________________________________________________________\n",
      "None\n",
      "Approximate time remaining of the training: 51.0  min.,  12.831226158142089  sec.\n",
      "Iteration number: 8 / 25\n",
      "Starting training data creation:\n",
      "Defining the buffer zone:\n",
      "(inl_min, inl_max, xl_min, xl_max, t_min, t_max)\n",
      "( 132 , 718 , 332 , 1218 , 132 , 1720 )\n",
      "( 32 , 918 , 32 , 429 )\n",
      "Finished creating 20000 examples!\n",
      "Not using data augmentation.\n",
      "Train on 16000 samples, validate on 4000 samples\n",
      "Epoch 1/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.1246 - acc: 0.9825 - val_loss: 0.0443 - val_acc: 0.9932\n",
      "Epoch 2/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0938 - acc: 0.9882 - val_loss: 0.0317 - val_acc: 0.9972\n",
      "Epoch 3/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0777 - acc: 0.9904 - val_loss: 0.0312 - val_acc: 0.9975\n",
      "Epoch 4/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0659 - acc: 0.9910 - val_loss: 0.0311 - val_acc: 0.9975\n",
      "Epoch 5/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0616 - acc: 0.9919 - val_loss: 0.0306 - val_acc: 0.9975\n",
      "Epoch 6/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0660 - acc: 0.9915 - val_loss: 0.0314 - val_acc: 0.9975\n",
      "Epoch 7/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0545 - acc: 0.9924 - val_loss: 0.0310 - val_acc: 0.9975\n",
      "Epoch 8/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0563 - acc: 0.9920 - val_loss: 0.0310 - val_acc: 0.9975\n",
      "Epoch 9/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0626 - acc: 0.9922 - val_loss: 0.0305 - val_acc: 0.9975\n",
      "Epoch 10/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0606 - acc: 0.9924 - val_loss: 0.0309 - val_acc: 0.9975\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv_layer1 (Conv2D)         (None, 17, 17, 50)        1300      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 17, 17, 50)        200       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 17, 17, 50)        0         \n",
      "_________________________________________________________________\n",
      "conv_layer2 (Conv2D)         (None, 9, 9, 50)          22550     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 9, 9, 50)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 9, 9, 50)          200       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 9, 9, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv_layer3 (Conv2D)         (None, 5, 5, 50)          22550     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 5, 5, 50)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 5, 5, 50)          200       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 5, 5, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv_layer4 (Conv2D)         (None, 3, 3, 50)          22550     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 3, 3, 50)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 3, 3, 50)          200       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 3, 3, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv_layer5 (Conv2D)         (None, 2, 2, 50)          22550     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_layer1 (Dense)         (None, 50)                10050     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 50)                200       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "attribute_layer (Dense)      (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "pre-softmax_layer (Dense)    (None, 9)                 99        \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 9)                 36        \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 9)                 0         \n",
      "=================================================================\n",
      "Total params: 103,235\n",
      "Trainable params: 102,697\n",
      "Non-trainable params: 538\n",
      "_________________________________________________________________\n",
      "None\n",
      "Approximate time remaining of the training: 48.0  min.,  18.11838026046753  sec.\n",
      "Iteration number: 9 / 25\n",
      "Starting training data creation:\n",
      "Defining the buffer zone:\n",
      "(inl_min, inl_max, xl_min, xl_max, t_min, t_max)\n",
      "( 132 , 718 , 332 , 1218 , 132 , 1720 )\n",
      "( 32 , 918 , 32 , 429 )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating 20000 examples!\n",
      "Not using data augmentation.\n",
      "Train on 16000 samples, validate on 4000 samples\n",
      "Epoch 1/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.1679 - acc: 0.9808 - val_loss: 0.0510 - val_acc: 0.9938\n",
      "Epoch 2/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0997 - acc: 0.9876 - val_loss: 0.0289 - val_acc: 0.9968\n",
      "Epoch 3/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0718 - acc: 0.9914 - val_loss: 0.0270 - val_acc: 0.9972\n",
      "Epoch 4/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0672 - acc: 0.9919 - val_loss: 0.0272 - val_acc: 0.9972\n",
      "Epoch 5/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0722 - acc: 0.9906 - val_loss: 0.0285 - val_acc: 0.9970\n",
      "Epoch 6/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0626 - acc: 0.9909 - val_loss: 0.0279 - val_acc: 0.9970\n",
      "Epoch 7/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0821 - acc: 0.9899 - val_loss: 0.0280 - val_acc: 0.9970\n",
      "Epoch 8/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0672 - acc: 0.9912 - val_loss: 0.0290 - val_acc: 0.9970\n",
      "Epoch 9/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0718 - acc: 0.9913 - val_loss: 0.0276 - val_acc: 0.9972\n",
      "Epoch 10/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0740 - acc: 0.9911 - val_loss: 0.0263 - val_acc: 0.9975\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv_layer1 (Conv2D)         (None, 17, 17, 50)        1300      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 17, 17, 50)        200       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 17, 17, 50)        0         \n",
      "_________________________________________________________________\n",
      "conv_layer2 (Conv2D)         (None, 9, 9, 50)          22550     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 9, 9, 50)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 9, 9, 50)          200       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 9, 9, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv_layer3 (Conv2D)         (None, 5, 5, 50)          22550     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 5, 5, 50)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 5, 5, 50)          200       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 5, 5, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv_layer4 (Conv2D)         (None, 3, 3, 50)          22550     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 3, 3, 50)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 3, 3, 50)          200       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 3, 3, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv_layer5 (Conv2D)         (None, 2, 2, 50)          22550     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_layer1 (Dense)         (None, 50)                10050     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 50)                200       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "attribute_layer (Dense)      (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "pre-softmax_layer (Dense)    (None, 9)                 99        \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 9)                 36        \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 9)                 0         \n",
      "=================================================================\n",
      "Total params: 103,235\n",
      "Trainable params: 102,697\n",
      "Non-trainable params: 538\n",
      "_________________________________________________________________\n",
      "None\n",
      "Approximate time remaining of the training: 45.0  min.,  23.405534362792967  sec.\n",
      "Iteration number: 10 / 25\n",
      "Starting training data creation:\n",
      "Defining the buffer zone:\n",
      "(inl_min, inl_max, xl_min, xl_max, t_min, t_max)\n",
      "( 132 , 718 , 332 , 1218 , 132 , 1720 )\n",
      "( 32 , 918 , 32 , 429 )\n",
      "Finished creating 20000 examples!\n",
      "Not using data augmentation.\n",
      "Train on 16000 samples, validate on 4000 samples\n",
      "Epoch 1/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.2128 - acc: 0.9751 - val_loss: 0.1465 - val_acc: 0.9722\n",
      "Epoch 2/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.1132 - acc: 0.9861 - val_loss: 0.0175 - val_acc: 0.9982\n",
      "Epoch 3/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0776 - acc: 0.9895 - val_loss: 0.0156 - val_acc: 0.9982\n",
      "Epoch 4/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0821 - acc: 0.9904 - val_loss: 0.0160 - val_acc: 0.9982\n",
      "Epoch 5/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0800 - acc: 0.9899 - val_loss: 0.0158 - val_acc: 0.9982\n",
      "Epoch 6/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0605 - acc: 0.9913 - val_loss: 0.0154 - val_acc: 0.9982\n",
      "Epoch 7/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0690 - acc: 0.9910 - val_loss: 0.0155 - val_acc: 0.9982\n",
      "Epoch 8/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0719 - acc: 0.9899 - val_loss: 0.0162 - val_acc: 0.9982\n",
      "Epoch 9/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0730 - acc: 0.9908 - val_loss: 0.0154 - val_acc: 0.9982\n",
      "Epoch 10/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0663 - acc: 0.9907 - val_loss: 0.0171 - val_acc: 0.9982\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv_layer1 (Conv2D)         (None, 17, 17, 50)        1300      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 17, 17, 50)        200       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 17, 17, 50)        0         \n",
      "_________________________________________________________________\n",
      "conv_layer2 (Conv2D)         (None, 9, 9, 50)          22550     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 9, 9, 50)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 9, 9, 50)          200       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 9, 9, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv_layer3 (Conv2D)         (None, 5, 5, 50)          22550     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 5, 5, 50)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 5, 5, 50)          200       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 5, 5, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv_layer4 (Conv2D)         (None, 3, 3, 50)          22550     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 3, 3, 50)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 3, 3, 50)          200       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 3, 3, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv_layer5 (Conv2D)         (None, 2, 2, 50)          22550     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_layer1 (Dense)         (None, 50)                10050     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 50)                200       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "attribute_layer (Dense)      (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "pre-softmax_layer (Dense)    (None, 9)                 99        \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 9)                 36        \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 9)                 0         \n",
      "=================================================================\n",
      "Total params: 103,235\n",
      "Trainable params: 102,697\n",
      "Non-trainable params: 538\n",
      "_________________________________________________________________\n",
      "None\n",
      "Approximate time remaining of the training: 42.0  min.,  28.692688465118408  sec.\n",
      "Iteration number: 11 / 25\n",
      "Starting training data creation:\n",
      "Defining the buffer zone:\n",
      "(inl_min, inl_max, xl_min, xl_max, t_min, t_max)\n",
      "( 132 , 718 , 332 , 1218 , 132 , 1720 )\n",
      "( 32 , 918 , 32 , 429 )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating 20000 examples!\n",
      "Not using data augmentation.\n",
      "Train on 16000 samples, validate on 4000 samples\n",
      "Epoch 1/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.1195 - acc: 0.9848 - val_loss: 0.0168 - val_acc: 0.9982\n",
      "Epoch 2/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0908 - acc: 0.9883 - val_loss: 0.0080 - val_acc: 0.9992\n",
      "Epoch 3/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0723 - acc: 0.9906 - val_loss: 0.0086 - val_acc: 0.9992\n",
      "Epoch 4/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0660 - acc: 0.9910 - val_loss: 0.0085 - val_acc: 0.9990\n",
      "Epoch 5/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0751 - acc: 0.9911 - val_loss: 0.0082 - val_acc: 0.9992\n",
      "Epoch 6/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0647 - acc: 0.9920 - val_loss: 0.0080 - val_acc: 0.9990\n",
      "Epoch 7/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0819 - acc: 0.9900 - val_loss: 0.0081 - val_acc: 0.9990\n",
      "Epoch 8/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0563 - acc: 0.9921 - val_loss: 0.0076 - val_acc: 0.9992\n",
      "Epoch 9/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0722 - acc: 0.9907 - val_loss: 0.0081 - val_acc: 0.9992\n",
      "Epoch 10/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0552 - acc: 0.9926 - val_loss: 0.0081 - val_acc: 0.9990\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv_layer1 (Conv2D)         (None, 17, 17, 50)        1300      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 17, 17, 50)        200       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 17, 17, 50)        0         \n",
      "_________________________________________________________________\n",
      "conv_layer2 (Conv2D)         (None, 9, 9, 50)          22550     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 9, 9, 50)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 9, 9, 50)          200       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 9, 9, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv_layer3 (Conv2D)         (None, 5, 5, 50)          22550     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 5, 5, 50)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 5, 5, 50)          200       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 5, 5, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv_layer4 (Conv2D)         (None, 3, 3, 50)          22550     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 3, 3, 50)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 3, 3, 50)          200       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 3, 3, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv_layer5 (Conv2D)         (None, 2, 2, 50)          22550     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_layer1 (Dense)         (None, 50)                10050     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 50)                200       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "attribute_layer (Dense)      (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "pre-softmax_layer (Dense)    (None, 9)                 99        \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 9)                 36        \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 9)                 0         \n",
      "=================================================================\n",
      "Total params: 103,235\n",
      "Trainable params: 102,697\n",
      "Non-trainable params: 538\n",
      "_________________________________________________________________\n",
      "None\n",
      "Approximate time remaining of the training: 39.0  min.,  33.979842567444116  sec.\n",
      "Iteration number: 12 / 25\n",
      "Starting training data creation:\n",
      "Defining the buffer zone:\n",
      "(inl_min, inl_max, xl_min, xl_max, t_min, t_max)\n",
      "( 132 , 718 , 332 , 1218 , 132 , 1720 )\n",
      "( 32 , 918 , 32 , 429 )\n",
      "Finished creating 20000 examples!\n",
      "Not using data augmentation.\n",
      "Train on 16000 samples, validate on 4000 samples\n",
      "Epoch 1/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.1790 - acc: 0.9786 - val_loss: 0.0405 - val_acc: 0.9952\n",
      "Epoch 2/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.1011 - acc: 0.9875 - val_loss: 0.0201 - val_acc: 0.9982\n",
      "Epoch 3/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0747 - acc: 0.9905 - val_loss: 0.0212 - val_acc: 0.9980\n",
      "Epoch 4/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0688 - acc: 0.9914 - val_loss: 0.0205 - val_acc: 0.9980\n",
      "Epoch 5/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0721 - acc: 0.9896 - val_loss: 0.0207 - val_acc: 0.9982\n",
      "Epoch 6/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0582 - acc: 0.9923 - val_loss: 0.0206 - val_acc: 0.9978\n",
      "Epoch 7/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0698 - acc: 0.9906 - val_loss: 0.0208 - val_acc: 0.9980\n",
      "Epoch 8/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0664 - acc: 0.9912 - val_loss: 0.0221 - val_acc: 0.9975\n",
      "Epoch 9/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0753 - acc: 0.9906 - val_loss: 0.0218 - val_acc: 0.9980\n",
      "Epoch 10/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0669 - acc: 0.9919 - val_loss: 0.0210 - val_acc: 0.9985\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv_layer1 (Conv2D)         (None, 17, 17, 50)        1300      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 17, 17, 50)        200       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 17, 17, 50)        0         \n",
      "_________________________________________________________________\n",
      "conv_layer2 (Conv2D)         (None, 9, 9, 50)          22550     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 9, 9, 50)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 9, 9, 50)          200       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 9, 9, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv_layer3 (Conv2D)         (None, 5, 5, 50)          22550     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 5, 5, 50)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 5, 5, 50)          200       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 5, 5, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv_layer4 (Conv2D)         (None, 3, 3, 50)          22550     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 3, 3, 50)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 3, 3, 50)          200       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 3, 3, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv_layer5 (Conv2D)         (None, 2, 2, 50)          22550     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_layer1 (Dense)         (None, 50)                10050     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 50)                200       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "attribute_layer (Dense)      (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "pre-softmax_layer (Dense)    (None, 9)                 99        \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 9)                 36        \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 9)                 0         \n",
      "=================================================================\n",
      "Total params: 103,235\n",
      "Trainable params: 102,697\n",
      "Non-trainable params: 538\n",
      "_________________________________________________________________\n",
      "None\n",
      "Approximate time remaining of the training: 37.0  min.,  3.266996669769287  sec.\n",
      "Iteration number: 13 / 25\n",
      "Starting training data creation:\n",
      "Defining the buffer zone:\n",
      "(inl_min, inl_max, xl_min, xl_max, t_min, t_max)\n",
      "( 132 , 718 , 332 , 1218 , 132 , 1720 )\n",
      "( 32 , 918 , 32 , 429 )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating 20000 examples!\n",
      "Not using data augmentation.\n",
      "Train on 16000 samples, validate on 4000 samples\n",
      "Epoch 1/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.1240 - acc: 0.9836 - val_loss: 0.0247 - val_acc: 0.9958\n",
      "Epoch 2/10\n",
      "16000/16000 [==============================] - 16s 1ms/step - loss: 0.0684 - acc: 0.9904 - val_loss: 0.0114 - val_acc: 0.9980\n",
      "Epoch 3/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0700 - acc: 0.9914 - val_loss: 0.0113 - val_acc: 0.9978\n",
      "Epoch 4/10\n",
      "16000/16000 [==============================] - 16s 1ms/step - loss: 0.0664 - acc: 0.9908 - val_loss: 0.0127 - val_acc: 0.9972\n",
      "Epoch 5/10\n",
      "16000/16000 [==============================] - 16s 1ms/step - loss: 0.0544 - acc: 0.9912 - val_loss: 0.0114 - val_acc: 0.9975\n",
      "Epoch 6/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0547 - acc: 0.9920 - val_loss: 0.0116 - val_acc: 0.9978\n",
      "Epoch 7/10\n",
      "16000/16000 [==============================] - 16s 1ms/step - loss: 0.0720 - acc: 0.9911 - val_loss: 0.0112 - val_acc: 0.9982\n",
      "Epoch 8/10\n",
      "16000/16000 [==============================] - 16s 1ms/step - loss: 0.0600 - acc: 0.9910 - val_loss: 0.0110 - val_acc: 0.9982\n",
      "Epoch 9/10\n",
      "16000/16000 [==============================] - 16s 1ms/step - loss: 0.0625 - acc: 0.9921 - val_loss: 0.0115 - val_acc: 0.9972\n",
      "Epoch 10/10\n",
      "16000/16000 [==============================] - 16s 1ms/step - loss: 0.0564 - acc: 0.9914 - val_loss: 0.0130 - val_acc: 0.9970\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv_layer1 (Conv2D)         (None, 17, 17, 50)        1300      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 17, 17, 50)        200       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 17, 17, 50)        0         \n",
      "_________________________________________________________________\n",
      "conv_layer2 (Conv2D)         (None, 9, 9, 50)          22550     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 9, 9, 50)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 9, 9, 50)          200       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 9, 9, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv_layer3 (Conv2D)         (None, 5, 5, 50)          22550     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 5, 5, 50)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 5, 5, 50)          200       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 5, 5, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv_layer4 (Conv2D)         (None, 3, 3, 50)          22550     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 3, 3, 50)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 3, 3, 50)          200       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 3, 3, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv_layer5 (Conv2D)         (None, 2, 2, 50)          22550     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_layer1 (Dense)         (None, 50)                10050     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 50)                200       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "attribute_layer (Dense)      (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "pre-softmax_layer (Dense)    (None, 9)                 99        \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 9)                 36        \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 9)                 0         \n",
      "=================================================================\n",
      "Total params: 103,235\n",
      "Trainable params: 102,697\n",
      "Non-trainable params: 538\n",
      "_________________________________________________________________\n",
      "None\n",
      "Approximate time remaining of the training: 34.0  min.,  8.554150772094726  sec.\n",
      "Iteration number: 14 / 25\n",
      "Starting training data creation:\n",
      "Defining the buffer zone:\n",
      "(inl_min, inl_max, xl_min, xl_max, t_min, t_max)\n",
      "( 132 , 718 , 332 , 1218 , 132 , 1720 )\n",
      "( 32 , 918 , 32 , 429 )\n",
      "Finished creating 20000 examples!\n",
      "Not using data augmentation.\n",
      "Train on 16000 samples, validate on 4000 samples\n",
      "Epoch 1/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.1639 - acc: 0.9799 - val_loss: 0.0172 - val_acc: 0.9985\n",
      "Epoch 2/10\n",
      "16000/16000 [==============================] - 16s 1ms/step - loss: 0.0668 - acc: 0.9911 - val_loss: 0.0214 - val_acc: 0.9980\n",
      "Epoch 3/10\n",
      "16000/16000 [==============================] - 16s 1ms/step - loss: 0.0648 - acc: 0.9913 - val_loss: 0.0216 - val_acc: 0.9982\n",
      "Epoch 4/10\n",
      "16000/16000 [==============================] - 16s 1ms/step - loss: 0.0537 - acc: 0.9923 - val_loss: 0.0214 - val_acc: 0.9980\n",
      "Epoch 5/10\n",
      "16000/16000 [==============================] - 16s 1ms/step - loss: 0.0590 - acc: 0.9916 - val_loss: 0.0220 - val_acc: 0.9982\n",
      "Epoch 6/10\n",
      "16000/16000 [==============================] - 16s 1ms/step - loss: 0.0451 - acc: 0.9933 - val_loss: 0.0219 - val_acc: 0.9982\n",
      "Epoch 7/10\n",
      "16000/16000 [==============================] - 16s 1ms/step - loss: 0.0697 - acc: 0.9919 - val_loss: 0.0223 - val_acc: 0.9980\n",
      "Epoch 8/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0504 - acc: 0.9935 - val_loss: 0.0222 - val_acc: 0.9982\n",
      "Epoch 9/10\n",
      "16000/16000 [==============================] - 16s 1ms/step - loss: 0.0558 - acc: 0.9921 - val_loss: 0.0227 - val_acc: 0.9980\n",
      "Epoch 10/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0523 - acc: 0.9927 - val_loss: 0.0225 - val_acc: 0.9982\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv_layer1 (Conv2D)         (None, 17, 17, 50)        1300      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 17, 17, 50)        200       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 17, 17, 50)        0         \n",
      "_________________________________________________________________\n",
      "conv_layer2 (Conv2D)         (None, 9, 9, 50)          22550     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 9, 9, 50)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 9, 9, 50)          200       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 9, 9, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv_layer3 (Conv2D)         (None, 5, 5, 50)          22550     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 5, 5, 50)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 5, 5, 50)          200       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 5, 5, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv_layer4 (Conv2D)         (None, 3, 3, 50)          22550     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 3, 3, 50)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 3, 3, 50)          200       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 3, 3, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv_layer5 (Conv2D)         (None, 2, 2, 50)          22550     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_layer1 (Dense)         (None, 50)                10050     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 50)                200       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "attribute_layer (Dense)      (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "pre-softmax_layer (Dense)    (None, 9)                 99        \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 9)                 36        \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 9)                 0         \n",
      "=================================================================\n",
      "Total params: 103,235\n",
      "Trainable params: 102,697\n",
      "Non-trainable params: 538\n",
      "_________________________________________________________________\n",
      "None\n",
      "Approximate time remaining of the training: 31.0  min.,  13.841304874420166  sec.\n",
      "Iteration number: 15 / 25\n",
      "Starting training data creation:\n",
      "Defining the buffer zone:\n",
      "(inl_min, inl_max, xl_min, xl_max, t_min, t_max)\n",
      "( 132 , 718 , 332 , 1218 , 132 , 1720 )\n",
      "( 32 , 918 , 32 , 429 )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating 20000 examples!\n",
      "Not using data augmentation.\n",
      "Train on 16000 samples, validate on 4000 samples\n",
      "Epoch 1/10\n",
      "16000/16000 [==============================] - 16s 1ms/step - loss: 0.1242 - acc: 0.9849 - val_loss: 0.0681 - val_acc: 0.9922\n",
      "Epoch 2/10\n",
      "16000/16000 [==============================] - 16s 1ms/step - loss: 0.0733 - acc: 0.9907 - val_loss: 0.0237 - val_acc: 0.9980\n",
      "Epoch 3/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0591 - acc: 0.9916 - val_loss: 0.0255 - val_acc: 0.9975\n",
      "Epoch 4/10\n",
      "16000/16000 [==============================] - 16s 1ms/step - loss: 0.0741 - acc: 0.9916 - val_loss: 0.0254 - val_acc: 0.9978\n",
      "Epoch 5/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0610 - acc: 0.9914 - val_loss: 0.0259 - val_acc: 0.9975\n",
      "Epoch 6/10\n",
      "16000/16000 [==============================] - 16s 1ms/step - loss: 0.0595 - acc: 0.9912 - val_loss: 0.0260 - val_acc: 0.9978\n",
      "Epoch 7/10\n",
      "16000/16000 [==============================] - 16s 1ms/step - loss: 0.0484 - acc: 0.9926 - val_loss: 0.0251 - val_acc: 0.9975\n",
      "Epoch 8/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0566 - acc: 0.9920 - val_loss: 0.0257 - val_acc: 0.9978\n",
      "Epoch 9/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0615 - acc: 0.9919 - val_loss: 0.0247 - val_acc: 0.9975\n",
      "Epoch 10/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0601 - acc: 0.9921 - val_loss: 0.0252 - val_acc: 0.9975\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv_layer1 (Conv2D)         (None, 17, 17, 50)        1300      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 17, 17, 50)        200       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 17, 17, 50)        0         \n",
      "_________________________________________________________________\n",
      "conv_layer2 (Conv2D)         (None, 9, 9, 50)          22550     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 9, 9, 50)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 9, 9, 50)          200       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 9, 9, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv_layer3 (Conv2D)         (None, 5, 5, 50)          22550     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 5, 5, 50)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 5, 5, 50)          200       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 5, 5, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv_layer4 (Conv2D)         (None, 3, 3, 50)          22550     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 3, 3, 50)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 3, 3, 50)          200       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 3, 3, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv_layer5 (Conv2D)         (None, 2, 2, 50)          22550     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_layer1 (Dense)         (None, 50)                10050     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 50)                200       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "attribute_layer (Dense)      (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "pre-softmax_layer (Dense)    (None, 9)                 99        \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 9)                 36        \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 9)                 0         \n",
      "=================================================================\n",
      "Total params: 103,235\n",
      "Trainable params: 102,697\n",
      "Non-trainable params: 538\n",
      "_________________________________________________________________\n",
      "None\n",
      "Approximate time remaining of the training: 28.0  min.,  19.128458976745605  sec.\n",
      "Iteration number: 16 / 25\n",
      "Starting training data creation:\n",
      "Defining the buffer zone:\n",
      "(inl_min, inl_max, xl_min, xl_max, t_min, t_max)\n",
      "( 132 , 718 , 332 , 1218 , 132 , 1720 )\n",
      "( 32 , 918 , 32 , 429 )\n",
      "Finished creating 20000 examples!\n",
      "Not using data augmentation.\n",
      "Train on 16000 samples, validate on 4000 samples\n",
      "Epoch 1/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.1360 - acc: 0.9836 - val_loss: 0.0345 - val_acc: 0.9965\n",
      "Epoch 2/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0877 - acc: 0.9900 - val_loss: 0.0168 - val_acc: 0.9982\n",
      "Epoch 3/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0767 - acc: 0.9904 - val_loss: 0.0164 - val_acc: 0.9982\n",
      "Epoch 4/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0753 - acc: 0.9909 - val_loss: 0.0167 - val_acc: 0.9982\n",
      "Epoch 5/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0769 - acc: 0.9909 - val_loss: 0.0161 - val_acc: 0.9982\n",
      "Epoch 6/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0705 - acc: 0.9916 - val_loss: 0.0162 - val_acc: 0.9985\n",
      "Epoch 7/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0627 - acc: 0.9924 - val_loss: 0.0169 - val_acc: 0.9985\n",
      "Epoch 8/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0643 - acc: 0.9916 - val_loss: 0.0154 - val_acc: 0.9982\n",
      "Epoch 9/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0661 - acc: 0.9912 - val_loss: 0.0166 - val_acc: 0.9982\n",
      "Epoch 10/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0714 - acc: 0.9912 - val_loss: 0.0168 - val_acc: 0.9985\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv_layer1 (Conv2D)         (None, 17, 17, 50)        1300      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 17, 17, 50)        200       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 17, 17, 50)        0         \n",
      "_________________________________________________________________\n",
      "conv_layer2 (Conv2D)         (None, 9, 9, 50)          22550     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 9, 9, 50)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 9, 9, 50)          200       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 9, 9, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv_layer3 (Conv2D)         (None, 5, 5, 50)          22550     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 5, 5, 50)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 5, 5, 50)          200       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 5, 5, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv_layer4 (Conv2D)         (None, 3, 3, 50)          22550     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 3, 3, 50)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 3, 3, 50)          200       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 3, 3, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv_layer5 (Conv2D)         (None, 2, 2, 50)          22550     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_layer1 (Dense)         (None, 50)                10050     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 50)                200       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "attribute_layer (Dense)      (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "pre-softmax_layer (Dense)    (None, 9)                 99        \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 9)                 36        \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 9)                 0         \n",
      "=================================================================\n",
      "Total params: 103,235\n",
      "Trainable params: 102,697\n",
      "Non-trainable params: 538\n",
      "_________________________________________________________________\n",
      "None\n",
      "Approximate time remaining of the training: 25.0  min.,  24.415613079071044  sec.\n",
      "Iteration number: 17 / 25\n",
      "Starting training data creation:\n",
      "Defining the buffer zone:\n",
      "(inl_min, inl_max, xl_min, xl_max, t_min, t_max)\n",
      "( 132 , 718 , 332 , 1218 , 132 , 1720 )\n",
      "( 32 , 918 , 32 , 429 )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating 20000 examples!\n",
      "Not using data augmentation.\n",
      "Train on 16000 samples, validate on 4000 samples\n",
      "Epoch 1/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.1229 - acc: 0.9845 - val_loss: 0.0208 - val_acc: 0.9965\n",
      "Epoch 2/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0581 - acc: 0.9920 - val_loss: 0.0128 - val_acc: 0.9980\n",
      "Epoch 3/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0562 - acc: 0.9923 - val_loss: 0.0128 - val_acc: 0.9978\n",
      "Epoch 4/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0566 - acc: 0.9920 - val_loss: 0.0141 - val_acc: 0.9978\n",
      "Epoch 5/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0494 - acc: 0.9928 - val_loss: 0.0128 - val_acc: 0.9980\n",
      "Epoch 6/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0452 - acc: 0.9936 - val_loss: 0.0134 - val_acc: 0.9978\n",
      "Epoch 7/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0527 - acc: 0.9928 - val_loss: 0.0130 - val_acc: 0.9980\n",
      "Epoch 8/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0567 - acc: 0.9926 - val_loss: 0.0125 - val_acc: 0.9980\n",
      "Epoch 9/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0403 - acc: 0.9939 - val_loss: 0.0133 - val_acc: 0.9980\n",
      "Epoch 10/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0549 - acc: 0.9931 - val_loss: 0.0120 - val_acc: 0.9978\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv_layer1 (Conv2D)         (None, 17, 17, 50)        1300      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 17, 17, 50)        200       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 17, 17, 50)        0         \n",
      "_________________________________________________________________\n",
      "conv_layer2 (Conv2D)         (None, 9, 9, 50)          22550     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 9, 9, 50)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 9, 9, 50)          200       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 9, 9, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv_layer3 (Conv2D)         (None, 5, 5, 50)          22550     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 5, 5, 50)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 5, 5, 50)          200       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 5, 5, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv_layer4 (Conv2D)         (None, 3, 3, 50)          22550     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 3, 3, 50)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 3, 3, 50)          200       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 3, 3, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv_layer5 (Conv2D)         (None, 2, 2, 50)          22550     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_layer1 (Dense)         (None, 50)                10050     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 50)                200       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "attribute_layer (Dense)      (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "pre-softmax_layer (Dense)    (None, 9)                 99        \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 9)                 36        \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 9)                 0         \n",
      "=================================================================\n",
      "Total params: 103,235\n",
      "Trainable params: 102,697\n",
      "Non-trainable params: 538\n",
      "_________________________________________________________________\n",
      "None\n",
      "Approximate time remaining of the training: 22.0  min.,  29.70276718139648  sec.\n",
      "Iteration number: 18 / 25\n",
      "Starting training data creation:\n",
      "Defining the buffer zone:\n",
      "(inl_min, inl_max, xl_min, xl_max, t_min, t_max)\n",
      "( 132 , 718 , 332 , 1218 , 132 , 1720 )\n",
      "( 32 , 918 , 32 , 429 )\n",
      "Finished creating 20000 examples!\n",
      "Not using data augmentation.\n",
      "Train on 16000 samples, validate on 4000 samples\n",
      "Epoch 1/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.1628 - acc: 0.9804 - val_loss: 0.0176 - val_acc: 0.9978\n",
      "Epoch 2/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0807 - acc: 0.9900 - val_loss: 0.0122 - val_acc: 0.9992\n",
      "Epoch 3/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0745 - acc: 0.9920 - val_loss: 0.0123 - val_acc: 0.9992\n",
      "Epoch 4/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0664 - acc: 0.9914 - val_loss: 0.0123 - val_acc: 0.9992\n",
      "Epoch 5/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0698 - acc: 0.9913 - val_loss: 0.0124 - val_acc: 0.9990\n",
      "Epoch 6/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0594 - acc: 0.9926 - val_loss: 0.0123 - val_acc: 0.9992\n",
      "Epoch 7/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0698 - acc: 0.9913 - val_loss: 0.0121 - val_acc: 0.9990\n",
      "Epoch 8/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0632 - acc: 0.9918 - val_loss: 0.0117 - val_acc: 0.9990\n",
      "Epoch 9/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0654 - acc: 0.9919 - val_loss: 0.0124 - val_acc: 0.9990\n",
      "Epoch 10/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0503 - acc: 0.9926 - val_loss: 0.0121 - val_acc: 0.9992\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv_layer1 (Conv2D)         (None, 17, 17, 50)        1300      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 17, 17, 50)        200       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 17, 17, 50)        0         \n",
      "_________________________________________________________________\n",
      "conv_layer2 (Conv2D)         (None, 9, 9, 50)          22550     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 9, 9, 50)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 9, 9, 50)          200       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 9, 9, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv_layer3 (Conv2D)         (None, 5, 5, 50)          22550     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 5, 5, 50)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 5, 5, 50)          200       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 5, 5, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv_layer4 (Conv2D)         (None, 3, 3, 50)          22550     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 3, 3, 50)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 3, 3, 50)          200       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 3, 3, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv_layer5 (Conv2D)         (None, 2, 2, 50)          22550     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_layer1 (Dense)         (None, 50)                10050     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 50)                200       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "attribute_layer (Dense)      (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "pre-softmax_layer (Dense)    (None, 9)                 99        \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 9)                 36        \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 9)                 0         \n",
      "=================================================================\n",
      "Total params: 103,235\n",
      "Trainable params: 102,697\n",
      "Non-trainable params: 538\n",
      "_________________________________________________________________\n",
      "None\n",
      "Approximate time remaining of the training: 19.0  min.,  34.98992128372206  sec.\n",
      "Iteration number: 19 / 25\n",
      "Starting training data creation:\n",
      "Defining the buffer zone:\n",
      "(inl_min, inl_max, xl_min, xl_max, t_min, t_max)\n",
      "( 132 , 718 , 332 , 1218 , 132 , 1720 )\n",
      "( 32 , 918 , 32 , 429 )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating 20000 examples!\n",
      "Not using data augmentation.\n",
      "Train on 16000 samples, validate on 4000 samples\n",
      "Epoch 1/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.1177 - acc: 0.9855 - val_loss: 0.3052 - val_acc: 0.9685\n",
      "Epoch 2/10\n",
      "16000/16000 [==============================] - 16s 1ms/step - loss: 0.0715 - acc: 0.9901 - val_loss: 0.0158 - val_acc: 0.9982\n",
      "Epoch 3/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0520 - acc: 0.9928 - val_loss: 0.0143 - val_acc: 0.9982\n",
      "Epoch 4/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0603 - acc: 0.9919 - val_loss: 0.0148 - val_acc: 0.9982\n",
      "Epoch 5/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0539 - acc: 0.9925 - val_loss: 0.0144 - val_acc: 0.9988\n",
      "Epoch 6/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0488 - acc: 0.9935 - val_loss: 0.0147 - val_acc: 0.9985\n",
      "Epoch 7/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0668 - acc: 0.9916 - val_loss: 0.0145 - val_acc: 0.9985\n",
      "Epoch 8/10\n",
      "16000/16000 [==============================] - 16s 1ms/step - loss: 0.0534 - acc: 0.9926 - val_loss: 0.0144 - val_acc: 0.9985\n",
      "Epoch 9/10\n",
      "16000/16000 [==============================] - 16s 1ms/step - loss: 0.0606 - acc: 0.9921 - val_loss: 0.0143 - val_acc: 0.9985\n",
      "Epoch 10/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0548 - acc: 0.9927 - val_loss: 0.0144 - val_acc: 0.9985\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv_layer1 (Conv2D)         (None, 17, 17, 50)        1300      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 17, 17, 50)        200       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 17, 17, 50)        0         \n",
      "_________________________________________________________________\n",
      "conv_layer2 (Conv2D)         (None, 9, 9, 50)          22550     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 9, 9, 50)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 9, 9, 50)          200       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 9, 9, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv_layer3 (Conv2D)         (None, 5, 5, 50)          22550     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 5, 5, 50)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 5, 5, 50)          200       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 5, 5, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv_layer4 (Conv2D)         (None, 3, 3, 50)          22550     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 3, 3, 50)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 3, 3, 50)          200       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 3, 3, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv_layer5 (Conv2D)         (None, 2, 2, 50)          22550     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_layer1 (Dense)         (None, 50)                10050     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 50)                200       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "attribute_layer (Dense)      (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "pre-softmax_layer (Dense)    (None, 9)                 99        \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 9)                 36        \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 9)                 0         \n",
      "=================================================================\n",
      "Total params: 103,235\n",
      "Trainable params: 102,697\n",
      "Non-trainable params: 538\n",
      "_________________________________________________________________\n",
      "None\n",
      "Approximate time remaining of the training: 17.0  min.,  4.277075386047363  sec.\n",
      "Iteration number: 20 / 25\n",
      "Starting training data creation:\n",
      "Defining the buffer zone:\n",
      "(inl_min, inl_max, xl_min, xl_max, t_min, t_max)\n",
      "( 132 , 718 , 332 , 1218 , 132 , 1720 )\n",
      "( 32 , 918 , 32 , 429 )\n",
      "Finished creating 20000 examples!\n",
      "Not using data augmentation.\n",
      "Train on 16000 samples, validate on 4000 samples\n",
      "Epoch 1/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.1160 - acc: 0.9864 - val_loss: 0.0277 - val_acc: 0.9972\n",
      "Epoch 2/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0568 - acc: 0.9928 - val_loss: 0.0242 - val_acc: 0.9975\n",
      "Epoch 3/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0494 - acc: 0.9929 - val_loss: 0.0262 - val_acc: 0.9972\n",
      "Epoch 4/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0574 - acc: 0.9926 - val_loss: 0.0249 - val_acc: 0.9975\n",
      "Epoch 5/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0664 - acc: 0.9922 - val_loss: 0.0254 - val_acc: 0.9975\n",
      "Epoch 6/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0557 - acc: 0.9925 - val_loss: 0.0255 - val_acc: 0.9975\n",
      "Epoch 7/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0789 - acc: 0.9909 - val_loss: 0.0254 - val_acc: 0.9975\n",
      "Epoch 8/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0600 - acc: 0.9930 - val_loss: 0.0259 - val_acc: 0.9972\n",
      "Epoch 9/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0542 - acc: 0.9926 - val_loss: 0.0259 - val_acc: 0.9972\n",
      "Epoch 10/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0755 - acc: 0.9912 - val_loss: 0.0259 - val_acc: 0.9975\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv_layer1 (Conv2D)         (None, 17, 17, 50)        1300      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 17, 17, 50)        200       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 17, 17, 50)        0         \n",
      "_________________________________________________________________\n",
      "conv_layer2 (Conv2D)         (None, 9, 9, 50)          22550     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 9, 9, 50)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 9, 9, 50)          200       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 9, 9, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv_layer3 (Conv2D)         (None, 5, 5, 50)          22550     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 5, 5, 50)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 5, 5, 50)          200       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 5, 5, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv_layer4 (Conv2D)         (None, 3, 3, 50)          22550     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 3, 3, 50)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 3, 3, 50)          200       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 3, 3, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv_layer5 (Conv2D)         (None, 2, 2, 50)          22550     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_layer1 (Dense)         (None, 50)                10050     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 50)                200       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "attribute_layer (Dense)      (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "pre-softmax_layer (Dense)    (None, 9)                 99        \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 9)                 36        \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 9)                 0         \n",
      "=================================================================\n",
      "Total params: 103,235\n",
      "Trainable params: 102,697\n",
      "Non-trainable params: 538\n",
      "_________________________________________________________________\n",
      "None\n",
      "Approximate time remaining of the training: 14.0  min.,  9.564229488372803  sec.\n",
      "Iteration number: 21 / 25\n",
      "Starting training data creation:\n",
      "Defining the buffer zone:\n",
      "(inl_min, inl_max, xl_min, xl_max, t_min, t_max)\n",
      "( 132 , 718 , 332 , 1218 , 132 , 1720 )\n",
      "( 32 , 918 , 32 , 429 )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating 20000 examples!\n",
      "Not using data augmentation.\n",
      "Train on 16000 samples, validate on 4000 samples\n",
      "Epoch 1/10\n",
      "16000/16000 [==============================] - 16s 1ms/step - loss: 0.1274 - acc: 0.9851 - val_loss: 0.0959 - val_acc: 0.9870\n",
      "Epoch 2/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0893 - acc: 0.9901 - val_loss: 0.0275 - val_acc: 0.9975\n",
      "Epoch 3/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0607 - acc: 0.9928 - val_loss: 0.0257 - val_acc: 0.9978\n",
      "Epoch 4/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0569 - acc: 0.9929 - val_loss: 0.0260 - val_acc: 0.9978\n",
      "Epoch 5/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0591 - acc: 0.9924 - val_loss: 0.0261 - val_acc: 0.9978\n",
      "Epoch 6/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0628 - acc: 0.9926 - val_loss: 0.0258 - val_acc: 0.9978\n",
      "Epoch 7/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0661 - acc: 0.9919 - val_loss: 0.0255 - val_acc: 0.9978\n",
      "Epoch 8/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0597 - acc: 0.9919 - val_loss: 0.0254 - val_acc: 0.9978\n",
      "Epoch 9/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0729 - acc: 0.9912 - val_loss: 0.0255 - val_acc: 0.9978\n",
      "Epoch 10/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0629 - acc: 0.9921 - val_loss: 0.0251 - val_acc: 0.9980\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv_layer1 (Conv2D)         (None, 17, 17, 50)        1300      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 17, 17, 50)        200       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 17, 17, 50)        0         \n",
      "_________________________________________________________________\n",
      "conv_layer2 (Conv2D)         (None, 9, 9, 50)          22550     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 9, 9, 50)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 9, 9, 50)          200       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 9, 9, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv_layer3 (Conv2D)         (None, 5, 5, 50)          22550     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 5, 5, 50)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 5, 5, 50)          200       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 5, 5, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv_layer4 (Conv2D)         (None, 3, 3, 50)          22550     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 3, 3, 50)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 3, 3, 50)          200       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 3, 3, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv_layer5 (Conv2D)         (None, 2, 2, 50)          22550     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_layer1 (Dense)         (None, 50)                10050     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 50)                200       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "attribute_layer (Dense)      (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "pre-softmax_layer (Dense)    (None, 9)                 99        \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 9)                 36        \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 9)                 0         \n",
      "=================================================================\n",
      "Total params: 103,235\n",
      "Trainable params: 102,697\n",
      "Non-trainable params: 538\n",
      "_________________________________________________________________\n",
      "None\n",
      "Approximate time remaining of the training: 11.0  min.,  14.85138359069824  sec.\n",
      "Iteration number: 22 / 25\n",
      "Starting training data creation:\n",
      "Defining the buffer zone:\n",
      "(inl_min, inl_max, xl_min, xl_max, t_min, t_max)\n",
      "( 132 , 718 , 332 , 1218 , 132 , 1720 )\n",
      "( 32 , 918 , 32 , 429 )\n",
      "Finished creating 20000 examples!\n",
      "Not using data augmentation.\n",
      "Train on 16000 samples, validate on 4000 samples\n",
      "Epoch 1/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.1227 - acc: 0.9853 - val_loss: 0.0623 - val_acc: 0.9920\n",
      "Epoch 2/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0923 - acc: 0.9896 - val_loss: 0.0455 - val_acc: 0.9960\n",
      "Epoch 3/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0526 - acc: 0.9937 - val_loss: 0.0443 - val_acc: 0.9962\n",
      "Epoch 4/10\n",
      "16000/16000 [==============================] - 16s 1ms/step - loss: 0.0644 - acc: 0.9920 - val_loss: 0.0431 - val_acc: 0.9962\n",
      "Epoch 5/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0505 - acc: 0.9926 - val_loss: 0.0441 - val_acc: 0.9965\n",
      "Epoch 6/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0654 - acc: 0.9912 - val_loss: 0.0467 - val_acc: 0.9962\n",
      "Epoch 7/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0752 - acc: 0.9914 - val_loss: 0.0451 - val_acc: 0.9962\n",
      "Epoch 8/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0551 - acc: 0.9924 - val_loss: 0.0437 - val_acc: 0.9962\n",
      "Epoch 9/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0704 - acc: 0.9914 - val_loss: 0.0454 - val_acc: 0.9962\n",
      "Epoch 10/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0653 - acc: 0.9924 - val_loss: 0.0438 - val_acc: 0.9965\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv_layer1 (Conv2D)         (None, 17, 17, 50)        1300      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 17, 17, 50)        200       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 17, 17, 50)        0         \n",
      "_________________________________________________________________\n",
      "conv_layer2 (Conv2D)         (None, 9, 9, 50)          22550     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 9, 9, 50)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 9, 9, 50)          200       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 9, 9, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv_layer3 (Conv2D)         (None, 5, 5, 50)          22550     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 5, 5, 50)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 5, 5, 50)          200       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 5, 5, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv_layer4 (Conv2D)         (None, 3, 3, 50)          22550     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 3, 3, 50)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 3, 3, 50)          200       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 3, 3, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv_layer5 (Conv2D)         (None, 2, 2, 50)          22550     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_layer1 (Dense)         (None, 50)                10050     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 50)                200       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "attribute_layer (Dense)      (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "pre-softmax_layer (Dense)    (None, 9)                 99        \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 9)                 36        \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 9)                 0         \n",
      "=================================================================\n",
      "Total params: 103,235\n",
      "Trainable params: 102,697\n",
      "Non-trainable params: 538\n",
      "_________________________________________________________________\n",
      "None\n",
      "Approximate time remaining of the training: 8.0  min.,  20.138537693023682  sec.\n",
      "Iteration number: 23 / 25\n",
      "Starting training data creation:\n",
      "Defining the buffer zone:\n",
      "(inl_min, inl_max, xl_min, xl_max, t_min, t_max)\n",
      "( 132 , 718 , 332 , 1218 , 132 , 1720 )\n",
      "( 32 , 918 , 32 , 429 )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating 20000 examples!\n",
      "Not using data augmentation.\n",
      "Train on 16000 samples, validate on 4000 samples\n",
      "Epoch 1/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.1148 - acc: 0.9859 - val_loss: 0.4240 - val_acc: 0.9587\n",
      "Epoch 2/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.1055 - acc: 0.9877 - val_loss: 0.0197 - val_acc: 0.9975\n",
      "Epoch 3/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0725 - acc: 0.9912 - val_loss: 0.0191 - val_acc: 0.9978\n",
      "Epoch 4/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0608 - acc: 0.9928 - val_loss: 0.0200 - val_acc: 0.9975\n",
      "Epoch 5/10\n",
      "16000/16000 [==============================] - 16s 1ms/step - loss: 0.0538 - acc: 0.9926 - val_loss: 0.0208 - val_acc: 0.9975\n",
      "Epoch 6/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0621 - acc: 0.9926 - val_loss: 0.0211 - val_acc: 0.9975\n",
      "Epoch 7/10\n",
      "16000/16000 [==============================] - 16s 1ms/step - loss: 0.0573 - acc: 0.9928 - val_loss: 0.0215 - val_acc: 0.9972\n",
      "Epoch 8/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0577 - acc: 0.9923 - val_loss: 0.0203 - val_acc: 0.9975\n",
      "Epoch 9/10\n",
      "16000/16000 [==============================] - 16s 1ms/step - loss: 0.0611 - acc: 0.9925 - val_loss: 0.0197 - val_acc: 0.9975\n",
      "Epoch 10/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0625 - acc: 0.9926 - val_loss: 0.0203 - val_acc: 0.9975\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv_layer1 (Conv2D)         (None, 17, 17, 50)        1300      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 17, 17, 50)        200       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 17, 17, 50)        0         \n",
      "_________________________________________________________________\n",
      "conv_layer2 (Conv2D)         (None, 9, 9, 50)          22550     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 9, 9, 50)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 9, 9, 50)          200       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 9, 9, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv_layer3 (Conv2D)         (None, 5, 5, 50)          22550     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 5, 5, 50)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 5, 5, 50)          200       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 5, 5, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv_layer4 (Conv2D)         (None, 3, 3, 50)          22550     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 3, 3, 50)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 3, 3, 50)          200       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 3, 3, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv_layer5 (Conv2D)         (None, 2, 2, 50)          22550     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_layer1 (Dense)         (None, 50)                10050     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 50)                200       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "attribute_layer (Dense)      (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "pre-softmax_layer (Dense)    (None, 9)                 99        \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 9)                 36        \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 9)                 0         \n",
      "=================================================================\n",
      "Total params: 103,235\n",
      "Trainable params: 102,697\n",
      "Non-trainable params: 538\n",
      "_________________________________________________________________\n",
      "None\n",
      "Approximate time remaining of the training: 5.0  min.,  25.42569179534912  sec.\n",
      "Iteration number: 24 / 25\n",
      "Starting training data creation:\n",
      "Defining the buffer zone:\n",
      "(inl_min, inl_max, xl_min, xl_max, t_min, t_max)\n",
      "( 132 , 718 , 332 , 1218 , 132 , 1720 )\n",
      "( 32 , 918 , 32 , 429 )\n",
      "Finished creating 20000 examples!\n",
      "Not using data augmentation.\n",
      "Train on 16000 samples, validate on 4000 samples\n",
      "Epoch 1/10\n",
      "16000/16000 [==============================] - 16s 1ms/step - loss: 0.0877 - acc: 0.9895 - val_loss: 0.0545 - val_acc: 0.9940\n",
      "Epoch 2/10\n",
      "16000/16000 [==============================] - 16s 1ms/step - loss: 0.0602 - acc: 0.9912 - val_loss: 0.0178 - val_acc: 0.9982\n",
      "Epoch 3/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0492 - acc: 0.9942 - val_loss: 0.0166 - val_acc: 0.9982\n",
      "Epoch 4/10\n",
      "16000/16000 [==============================] - 16s 1ms/step - loss: 0.0575 - acc: 0.9932 - val_loss: 0.0158 - val_acc: 0.9982\n",
      "Epoch 5/10\n",
      "16000/16000 [==============================] - 16s 1ms/step - loss: 0.0462 - acc: 0.9940 - val_loss: 0.0154 - val_acc: 0.9982\n",
      "Epoch 6/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0521 - acc: 0.9934 - val_loss: 0.0156 - val_acc: 0.9982\n",
      "Epoch 7/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0534 - acc: 0.9936 - val_loss: 0.0155 - val_acc: 0.9982\n",
      "Epoch 8/10\n",
      "16000/16000 [==============================] - 16s 1ms/step - loss: 0.0447 - acc: 0.9934 - val_loss: 0.0162 - val_acc: 0.9982\n",
      "Epoch 9/10\n",
      "16000/16000 [==============================] - 16s 1ms/step - loss: 0.0409 - acc: 0.9944 - val_loss: 0.0150 - val_acc: 0.9982\n",
      "Epoch 10/10\n",
      "16000/16000 [==============================] - 16s 1ms/step - loss: 0.0563 - acc: 0.9928 - val_loss: 0.0169 - val_acc: 0.9982\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv_layer1 (Conv2D)         (None, 17, 17, 50)        1300      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 17, 17, 50)        200       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 17, 17, 50)        0         \n",
      "_________________________________________________________________\n",
      "conv_layer2 (Conv2D)         (None, 9, 9, 50)          22550     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 9, 9, 50)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 9, 9, 50)          200       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 9, 9, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv_layer3 (Conv2D)         (None, 5, 5, 50)          22550     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 5, 5, 50)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 5, 5, 50)          200       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 5, 5, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv_layer4 (Conv2D)         (None, 3, 3, 50)          22550     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 3, 3, 50)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 3, 3, 50)          200       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 3, 3, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv_layer5 (Conv2D)         (None, 2, 2, 50)          22550     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_layer1 (Dense)         (None, 50)                10050     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 50)                200       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "attribute_layer (Dense)      (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "pre-softmax_layer (Dense)    (None, 9)                 99        \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 9)                 36        \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 9)                 0         \n",
      "=================================================================\n",
      "Total params: 103,235\n",
      "Trainable params: 102,697\n",
      "Non-trainable params: 538\n",
      "_________________________________________________________________\n",
      "None\n",
      "Approximate time remaining of the training: 171.18807649612427  sec.\n",
      "Iteration number: 25 / 25\n",
      "Starting training data creation:\n",
      "Defining the buffer zone:\n",
      "(inl_min, inl_max, xl_min, xl_max, t_min, t_max)\n",
      "( 132 , 718 , 332 , 1218 , 132 , 1720 )\n",
      "( 32 , 918 , 32 , 429 )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating 20000 examples!\n",
      "Not using data augmentation.\n",
      "Train on 16000 samples, validate on 4000 samples\n",
      "Epoch 1/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.1077 - acc: 0.9873 - val_loss: 0.2081 - val_acc: 0.9755\n",
      "Epoch 2/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.1104 - acc: 0.9882 - val_loss: 0.0383 - val_acc: 0.9960\n",
      "Epoch 3/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0565 - acc: 0.9925 - val_loss: 0.0369 - val_acc: 0.9960\n",
      "Epoch 4/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0782 - acc: 0.9906 - val_loss: 0.0349 - val_acc: 0.9965\n",
      "Epoch 5/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0654 - acc: 0.9926 - val_loss: 0.0359 - val_acc: 0.9965\n",
      "Epoch 6/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0671 - acc: 0.9922 - val_loss: 0.0353 - val_acc: 0.9965\n",
      "Epoch 7/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0719 - acc: 0.9921 - val_loss: 0.0367 - val_acc: 0.9960\n",
      "Epoch 8/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0717 - acc: 0.9918 - val_loss: 0.0357 - val_acc: 0.9965\n",
      "Epoch 9/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0667 - acc: 0.9924 - val_loss: 0.0356 - val_acc: 0.9965\n",
      "Epoch 10/10\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.0626 - acc: 0.9929 - val_loss: 0.0354 - val_acc: 0.9965\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv_layer1 (Conv2D)         (None, 17, 17, 50)        1300      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 17, 17, 50)        200       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 17, 17, 50)        0         \n",
      "_________________________________________________________________\n",
      "conv_layer2 (Conv2D)         (None, 9, 9, 50)          22550     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 9, 9, 50)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 9, 9, 50)          200       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 9, 9, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv_layer3 (Conv2D)         (None, 5, 5, 50)          22550     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 5, 5, 50)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 5, 5, 50)          200       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 5, 5, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv_layer4 (Conv2D)         (None, 3, 3, 50)          22550     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 3, 3, 50)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 3, 3, 50)          200       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 3, 3, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv_layer5 (Conv2D)         (None, 2, 2, 50)          22550     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_layer1 (Dense)         (None, 50)                10050     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 50)                200       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "attribute_layer (Dense)      (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "pre-softmax_layer (Dense)    (None, 9)                 99        \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 9)                 36        \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 9)                 0         \n",
      "=================================================================\n",
      "Total params: 103,235\n",
      "Trainable params: 102,697\n",
      "Non-trainable params: 538\n",
      "_________________________________________________________________\n",
      "None\n",
      "Approximate time remaining of the training: 0.0  sec.\n",
      "Saving model: ...\n",
      "Model saved.\n",
      "Total time elapsed during training: 1.0  hrs.,  5.950653302669525  min., \n"
     ]
    }
   ],
   "source": [
    "#### ---- Run an instance of the master function ----\n",
    "\n",
    "# Run the master function and save the output in the output dictionary output_dict\n",
    "output_dict1 = master(\n",
    "    segy_filename = filenames,     # Seismic filenames\n",
    "    inp_format = inp_res,     # Format of input seismic\n",
    "    cube_incr = cube_incr,     # Increments in each direction to create a training cube\n",
    "    train_dict = train_dict,     # Input training dictionary\n",
    "    pred_dict = pred_dict,     # Input prediction dictionary\n",
    "    mode = 'train'     # Input mode ('train', 'predict', or 'full' for both training AND prediction)\n",
    "    #mode = 'predict'     # Input mode ('train', 'predict', or 'full' for both training AND prediction)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-daedabd23c81>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_dict1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pred'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"spline16\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "pred = output_dict1['pred']\n",
    "print(pred.shape, np.max(pred), np.min(pred))\n",
    "plt.imshow(pred[0, :,:,0].T,interpolation=\"spline16\", vmin=0, vmax=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show additional details about the prediciton\n",
    "\"\"\"\n",
    "show_details(\n",
    "    filenames[0],\n",
    "    cube_incr,\n",
    "    pred,\n",
    "    inline = 400,\n",
    "    inl_start = 356,\n",
    "    xline = 400,\n",
    "    xl_start = 400,\n",
    "    slice_number = 200,\n",
    "    slice_incr = 3,\n",
    "    show_prob=False\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "### Save/load functions\n",
    "## returns a prediction cube\n",
    "## identical to the one saved\n",
    "#prediction = np.load('filename.npy')\n",
    "#\n",
    "## returns a compiled model\n",
    "## identical to the one saved\n",
    "#loaded_model = keras.models.load_model('filename.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
